<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.66">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous"><title data-react-helmet="true">Python Cheatsheet | Matt&#x27;s Docs</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="docusaurus_language" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Python Cheatsheet | Matt&#x27;s Docs"><meta data-react-helmet="true" name="description" content="Legend:"><meta data-react-helmet="true" property="og:description" content="Legend:"><meta data-react-helmet="true" property="og:url" content="https://crazoter.github.io/My-Docs/docs/markdown/python"><link data-react-helmet="true" rel="shortcut icon" href="/My-Docs/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://crazoter.github.io/My-Docs/docs/markdown/python"><link rel="stylesheet" href="/My-Docs/styles.cf8efcfc.css">
<link rel="preload" href="/My-Docs/styles.e0990858.js" as="script">
<link rel="preload" href="/My-Docs/runtime~main.b515bb10.js" as="script">
<link rel="preload" href="/My-Docs/main.11ed6bbe.js" as="script">
<link rel="preload" href="/My-Docs/1.ac610029.js" as="script">
<link rel="preload" href="/My-Docs/2.ff8ccd9c.js" as="script">
<link rel="preload" href="/My-Docs/42.523752d5.js" as="script">
<link rel="preload" href="/My-Docs/43.aea2c726.js" as="script">
<link rel="preload" href="/My-Docs/935f2afb.8c9dd23d.js" as="script">
<link rel="preload" href="/My-Docs/17896441.29e4bed3.js" as="script">
<link rel="preload" href="/My-Docs/991d0552.7e6e08b6.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand" href="/My-Docs/"><img class="navbar__logo" src="/My-Docs/img/ibuki.png" alt="My Site Logo"><strong class="navbar__title">Matt&#x27;s Docs</strong></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/My-Docs/docs/">Docs</a><a class="navbar__item navbar__link" href="/My-Docs/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/crazoter/My-Docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub</a><div class="react-toggle react-toggle--disabled displayOnlyInLargeViewport_2aTZ"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_BsTx">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_BsTx">ðŸŒž</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" disabled="" aria-label="Dark mode toggle" class="react-toggle-screenreader-only"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/My-Docs/"><img class="navbar__logo" src="/My-Docs/img/ibuki.png" alt="My Site Logo"><strong class="navbar__title">Matt&#x27;s Docs</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link navbar__link--active" href="/My-Docs/docs/">Docs</a></li><li class="menu__list-item"><a class="menu__link" href="/My-Docs/blog">Blog</a></li><li class="menu__list-item"><a href="https://github.com/crazoter/My-Docs" target="_blank" rel="noopener noreferrer" class="menu__link">GitHub</a></li></ul></div></div></div></nav><div class="main-wrapper"><div class="docPage_2gpo"><div class="docSidebarContainer_3_JD" role="complementary"><div class="sidebar_2urC"><div class="menu menu--responsive menu_5FrY"><button aria-label="Open Menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg aria-label="Menu" class="sidebarMenuIcon_Dm3K" xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 0 32 32" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Docusaurus</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/docusaurus/usage">Usage</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/docusaurus/doc1">Style Guide</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/docusaurus/mdx">Powered by MDX</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">AI</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/markdown/CS4246_summary">CS4246 Cheatsheet</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/markdown/ai_planning">AI Planning (CS4246, Reinforcement Learning)</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/markdown/computer_vision">Computer Vision</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/markdown/machine_learning">Machine Learning</a></li></ul></li><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#!">Languages</a><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/My-Docs/docs/markdown/python">Python Cheatsheet</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Math</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/markdown/math">Math</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Networks</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/markdown/network">Network</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/markdown/CS4226_summary">CS4226 Cheatsheet</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Software Development</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/markdown/formal_verification">Formal Verification</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Misc</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/">Tech lookup</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/markdown/code_snippets">Code Snippets</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Hobbies</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/manga_reviews">Manga Reviews</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/book_summaries">Book Summaries</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/My-Docs/docs/book_contemplations">Book Contemplations</a></li></ul></li></ul></div></div></div><main class="docMainContainer_3EyW"><div class="container padding-vert--lg docItemWrapper_1EkI"><div class="row"><div class="col docItemCol_2ASc"><div class="docItemContainer_3QWW"><article><header><h1 class="docTitle_1Lrw">Python Cheatsheet</h1></header><div class="markdown"><p>Legend:</p><ul><li>#: Number, used for differentiating variables</li><li>L#: List.</li><li>D#: Dictionary. </li><li>itr#: Iterable.</li><li>DF#: Dataframe</li><li>mltIdx#: MultiIndex</li><li>idx: Index</li><li>int#: Integer variable</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="pure-python"></a>Pure Python<a aria-hidden="true" tabindex="-1" class="hash-link" href="#pure-python" title="Direct link to heading">#</a></h2><ul><li>Exponentiation: val ** power</li><li>Type conversion: <em>type</em>(val), where <em>type</em> in {int, float, str, bool}</li><li>Iterables<ul><li><strong>Loop with Index</strong>: for idx, val in enumerate(itr)</li><li><strong>Generators (lazy loading iteration)</strong><ul><li>Creation: <ul><li><code>gen = iter(L / D / *range(i)*)</code></li><li><code>gen = (x for x in list)</code></li><li><code>gen = def fx(param): ... for x in param: yield x ...</code></li></ul></li><li>Use:    val = next(itr)</li></ul></li></ul></li><li>Lists<ul><li><strong>Init with List Comprehension</strong><ul><li>Format: <code>[ (value) for (var_name) in (iterable) if (predicate) ]</code><ul><li>e.g. [L[0] for elem in list]</li></ul></li></ul></li><li>List of tuples:<ul><li><strong>Convert L to L of indexed tuples:</strong><ul><li><code>enumerate(itr, start=int1) = [(int1,itr[0]), (int1+1,itr[0])...]</code></li></ul></li><li>Merge two lists into a list of tuples:<ul><li><code>zip(*L1*,*L2*)</code><ul><li>returns zipObject: [ (L1[0],L2[0]),  (L1[1],L2[1])... ]</li><li>Access zipObject contents: (*zipObj)</li></ul></li><li>Unzip: <code>zip(*zipObj)</code></li></ul></li></ul></li><li>Count occurrences: <code>list.count(obj)</code></li></ul></li><li>Dictionaries<ul><li><strong>Init with Dictionary Comprehension</strong><ul><li>Format: <code>{ (key : value) for (var_name) in (iterable) if (predicate) }</code><ul><li>e.g. {x : len(x) for x in list}</li></ul></li></ul></li><li><strong>Init from list of tuples</strong><ul><li><code>dict(zip(L1,L2))</code></li></ul></li></ul></li><li>Functions:<ul><li>Default params: x=default</li><li>Flexible list param: <code>f(*args)</code><ul><li>Usage: f(v1,v2,v3...)</li></ul></li><li>Flexible dict param: <code>f(**kwargs)</code><ul><li>Usage: f(k1=v1,k2=v2,k3=v3...)</li></ul></li><li>Multiple output: <ul><li>def fx(): return (x, y)</li><li>Multiple assignment:<ul><li>x,y = fx()</li></ul></li></ul></li><li>Global variables: <code>global varname</code></li><li>Nested functions:<ul><li>Variables &amp; params of external f() is accessible</li><li>The function itself can be returned</li><li>Modify variables from nested f(): <code>nonlocal varname</code></li></ul></li></ul></li><li>Functional Programming<ul><li><code>map((lambda a: (transformation)), L)</code></li><li><code>filter((lambda a: (predicate)), L)</code></li><li><code>reduce((lambda a,b: ...), L) = result</code><ul><li>Import: <code>from functools import reduce</code></li></ul></li><li>The lambda can be replaced with a concrete function</li></ul></li><li>Lambdas<ul><li><code>(lambda (params): (body))</code></li><li>e.g. (lambda a: a+1) â‰¡ def f(a): return a+1</li><li>No &quot;return&quot;</li><li>No multi-line</li></ul></li><li>Exception Handling<ul><li>try: ... </li><li>except: ... </li><li>raise <em>Error</em>(<em>msg</em>)<ul><li>Error = {ValueError, TypeError, YourOwnErrClass}</li></ul></li></ul></li><li>I/O<ul><li>Open file:<ul><li><code>with open(&#x27;filepath&#x27;) as file_var</code><ul><li><code>file_var.readline()</code>: returns None if empty</li></ul></li></ul></li><li>Get script directory:<ul><li><code>dir_path = os.path.dirname(os.path.realpath(__file__))</code></li></ul></li><li>Get path to file relative to script directory:<ul><li><code>local_file = os.path.join(dir_path, &#x27;path&#x27;, &#x27;to&#x27;, &#x27;local_file&#x27;)</code></li></ul></li></ul></li><li>Datetime<ul><li>Req: <code>import datetime as dt</code></li><li><code>dt.date.today()</code></li></ul></li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="libraries--modules"></a>Libraries / Modules<a aria-hidden="true" tabindex="-1" class="hash-link" href="#libraries--modules" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="regex"></a>Regex<a aria-hidden="true" tabindex="-1" class="hash-link" href="#regex" title="Direct link to heading">#</a></h3><ul><li><strong>Create Pattern</strong>: <code>pattern = re.compile(r&quot;regex_pattern&quot;)</code></li><li><strong>Match</strong>: <code>matches = re.match(pattern, str)</code><ul><li>Returns None if no matches found</li><li><strong>Get found values</strong>: <code>matches.group(n), n = 0 if no groups defined</code> </li></ul></li><li></li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="recordlinkage-join-datasets-wo-common-uid"></a>Recordlinkage (Join datasets w/o common UID)<a aria-hidden="true" tabindex="-1" class="hash-link" href="#recordlinkage-join-datasets-wo-common-uid" title="Direct link to heading">#</a></h3><ul><li><code>import recordlinkage</code></li><li>Purpose: <strong>Join different datasets when they don&#x27;t share a unique identifier.</strong> See <a href="https://recordlinkage.readthedocs.io/en/latest/ref-index.html" target="_blank" rel="noopener noreferrer">Documentation</a><ol><li><strong>Init an indexer</strong></li></ol><ul><li><code>idxr = recordlinkage.Index()</code></li></ul><ol start="2"><li>Blocking: only <strong>choose pairs of entries that have the same value under specified column</strong> (e.g. &quot;cuisine_type&quot;)</li></ol><ul><li><code>idxr.block(&quot;col_name&quot;)</code></li></ul><ol start="3"><li><strong>Generate said pairs of indexes</strong> which agree on the equal columns</li></ol><ul><li><code>mltIdx_pairs = idxr.index(df1, df2)</code><ul><li>Example pair: MultiIndex([(0,0),(0,1),(0,7),(1,0),(1,4)...])</li></ul></li></ul><ol start="4"><li><strong>Specify the columns to compare</strong> with a Compare object</li></ol><ul><li><code>comp = recordlinkage.Compare()</code><ul><li>Then, specify the columns to compare by:<ul><li><code>comp.exact(&#x27;col_nm_in_df1&#x27;, &#x27;col_nm_in_df2&#x27;, label=&#x27;new_lbl_in_new_df&#x27;)</code><ul><li>Entries must <strong>exact match</strong> in the columns</li><li>e.g. comp.exact(&#x27;city&#x27;, &#x27;city&#x27;, label=&#x27;city&#x27;)</li></ul></li><li><code>comp.string(&#x27;col_nm_in_df1&#x27;, &#x27;col_nm_in_df2&#x27;, label=&#x27;new_lbl_in_new_df&#x27;, threshold = dbl_frm_0-1)</code> (threshold usually 0.8)</li><li>Entries must be <strong>similar</strong> (in terms of string) in the columns</li></ul></li></ul></li></ul><ol start="5"><li>Apply the Compare object to <strong>get a dataframe highlighting potential matches</strong></li></ol><ul><li><code>df_pttl_mtchs = comp.compute(mltIdx_pairs, df1, df2)</code><ul><li>Structure of df_pttl_mtchs:<ul><li>Index / Col 0: mltIdx_pairs</li><li>Columns: columns used for comparison<ul><li>exact: 1 if equal else 0</li><li>string: 1 if threshold met, else 0</li></ul></li></ul></li></ul></li></ul><ol start="6"><li><strong>Filter matches</strong> from potential matches</li></ol><ul><li><code>df_mtchs = df_pttl_mtchs[df_pttl_mtchs.sum(axis=1) &gt;= 3]</code><ul><li>If the val == 1 then there&#x27;s a match on that column. This counts the number of matched columns, and filters by that.</li><li>In this case there were 3 columns so 3 was chosen</li></ul></li></ul><ol start="7"><li><strong>Select matched indexes</strong> for one of the DFs (in this case df2)<ul><li><code>idx_df2_mtched = df_mtchs.index.get_level_values(1)</code><ul><li>df_pttl_mtchs &amp; df_mtchs use a MultiIndex. </li><li>df_mtchs.index.get_level_values(0) = df1&#x27;s indexes, (1) = df2&#x27;s indexes</li></ul></li></ul></li><li><strong>From df2, remove entries that match df1&#x27;s entries</strong></li></ol><ul><li><code>df2_notInDf1 = df2[~df2.index.isin(idx_df2_mtched)]</code></li></ul><ol start="9"><li><strong>Join df1 and the new df2 entries</strong></li></ol><ul><li><code>df1.append(df2_notInDf1)</code></li></ul></li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="fuzzywuzzy-string-comparison"></a>fuzzywuzzy (String Comparison)<a aria-hidden="true" tabindex="-1" class="hash-link" href="#fuzzywuzzy-string-comparison" title="Direct link to heading">#</a></h3><ul><li><strong>Import</strong>: <code>from fuzzywuzzy import process</code></li><li><strong>Test similarity:</strong> <code>process.extract(&#x27;target_word&#x27;, arr_of_candidate_words, length_of_arr)</code><ul><li>Returns array of tuples: <code>[(&#x27;candidate_word&#x27;, similarity_score), ...]</code><ul><li>similarity_score: from 0 - 100, 100 as perfect, 80 as close enough</li></ul></li></ul></li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="missingno-visualize-missing-data"></a>missingno (Visualize missing data)<a aria-hidden="true" tabindex="-1" class="hash-link" href="#missingno-visualize-missing-data" title="Direct link to heading">#</a></h3><ul><li><code>import missingno as msno</code></li><li>msno.matrix(df_with_missingvals); plt.show()</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="scipystats-zscore"></a>scipy.stats (zscore)<a aria-hidden="true" tabindex="-1" class="hash-link" href="#scipystats-zscore" title="Direct link to heading">#</a></h3><ul><li><code>from scipy.stats import zscore</code></li><li>calculate zscore values: <code>zscore(df[&#x27;col&#x27;])</code><ul><li>z-score is the number of standard deviations by which an observation is above the mean - so if it is negative, it means the observation is below the mean.</li></ul></li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="textatistic-evaluate-word-readability"></a>Textatistic (Evaluate word readability)<a aria-hidden="true" tabindex="-1" class="hash-link" href="#textatistic-evaluate-word-readability" title="Direct link to heading">#</a></h3><ul><li><code>from textatistic import Textatistic</code></li><li>Compute scores: <code>scores = Textatistic(article/string).scores</code></li><li>Get Flesch score: <code>scores[&#x27;flesch_score&#x27;]</code></li><li>Get gunningfog: <code>scores[&#x27;gunningfog_score&#x27;]</code></li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="spacy-tokenization-and-lemmatization"></a>spacy (tokenization and lemmatization)<a aria-hidden="true" tabindex="-1" class="hash-link" href="#spacy-tokenization-and-lemmatization" title="Direct link to heading">#</a></h3><ul><li><code>import spacy</code></li><li>Tokenization</li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">import spacy</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Load the en_core_web_sm model which comes with the spaCy library (see https://spacy.io/models/en)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">nlp = spacy.load(&#x27;en_core_web_sm&#x27;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Create a Doc object</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">doc = nlp(gettysburg)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Generate the tokens</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">tokens = [token.text for token in doc]</span></div></div></div></div></div><ul><li>Lemmatization (accuracy dependent on moduel)</li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">import spacy</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Load the en_core_web_sm model</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">nlp = spacy.load(&#x27;en_core_web_sm&#x27;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Create a Doc object</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">doc = nlp(gettysburg)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Generate lemmas (accuracy dependent on model)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">lemmas = [token.lemma_ for token in doc]</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Convert lemmas into a string</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">print(&#x27; &#x27;.join(lemmas))</span></div></div></div></div></div><ul><li>Preprocess with lemmatization, removing non alphabeticals</li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Function to preprocess text</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">def preprocess(text):</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    # Create Doc object</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    doc = nlp(text, disable=[&#x27;ner&#x27;, &#x27;parser&#x27;])</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    # Generate lemmas</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    lemmas = [token.lemma_ for token in doc]</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    # Remove stopwords and non-alphabetic characters</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    a_lemmas = [lemma for lemma in lemmas </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">            if lemma.isalpha() and lemma not in stopwords]</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    return &#x27; &#x27;.join(a_lemmas)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">  </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Apply preprocess to ted[&#x27;transcript&#x27;]</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">ted[&#x27;transcript&#x27;] = ted[&#x27;transcript&#x27;].apply(preprocess)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">print(ted[&#x27;transcript&#x27;])</span></div></div></div></div></div><ul><li>POS (piece-of-speech) tagging </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Load the en_core_web_sm model</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">nlp = spacy.load(&#x27;en_core_web_sm&#x27;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Create a Doc object</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">doc = nlp(lotf)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Generate tokens and pos tags</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">pos = [(token.text, token.pos_) for token in doc]</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">print(pos) </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Output: [(&#x27;He&#x27;, &#x27;PRON&#x27;), (&#x27;found&#x27;, &#x27;VERB&#x27;), (&#x27;himself&#x27;, &#x27;PRON&#x27;), (&#x27;understanding&#x27;, &#x27;VERB&#x27;) ...</span></div></div></div></div></div><ul><li>Named Entities Recognition (NER)</li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Load the required model</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">nlp = spacy.load(&#x27;en_core_web_sm&#x27;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Create a Doc instance </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">text = &#x27;Sundar Pichai is the CEO of Google. Its headquarters is in Mountain View.&#x27;</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">doc = nlp(text)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Print all named entities and their labels</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">for ent in doc.ents:</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    print(ent.text, ent.label_)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">&quot;&quot;&quot;</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">Output:</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    Sundar Pichai ORG</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    Google ORG</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    Mountain View GPE</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">&quot;&quot;&quot;</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Alternatively:</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">def find_persons(text):</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">  # Create Doc object</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">  doc = nlp(text)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">  </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">  # Identify the persons</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">  persons = [ent.text for ent in doc.ents if ent.label_ == &#x27;PERSON&#x27;]</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">  </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">  # Return persons</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">  return persons</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">print(find_persons(tc))</span></div></div></div></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="matplotlibpyplot-graphs--images"></a>matplotlib.pyplot (Graphs &amp; Images)<a aria-hidden="true" tabindex="-1" class="hash-link" href="#matplotlibpyplot-graphs--images" title="Direct link to heading">#</a></h3><p><code>import matplotlib.pyplot as plt</code></p><ul><li><p>Think of <code>plt</code> as some kind of a global variable to attach stuff to</p></li><li><p>Change Styles:</p><ul><li><strong>Use style</strong>: <code>plt.style.use(style_name)</code></li><li><strong>Show available styles</strong>: <code>plt.style.available</code></li><li><strong>Improve the spacing between subplots</strong>: <code>plt.tight_layout()</code></li><li><strong>Hide gridlines</strong>: <code>plt.grid(&#x27;off&#x27;)</code></li><li><strong>Hide axes</strong>: <code>plt.axis(&#x27;off&#x27;)</code></li></ul></li><li><p>Graphs</p><ul><li><p>Create multiple graphs:</p><ul><li>Automatically using <code>plt.subplot(rows, columns, active_subplot_idx)</code><ul><li>Call the function with a new <code>active_subplot_idx</code> = row x rowlen * column to change the current graph.<ul><li><code>active_subplot_idx</code> starts from 1</li></ul></li></ul></li><li>Specify axes directly: </li><li><strong>Define bounding box (axes)</strong>: <code>plt.axes([xlower, ylower, width_%, height_%])</code>, args passed as a list<ul><li>Think of these as rectangle bounds of your current graph.<ul><li>e.g. if you want 2 graphs side-by-side: <ul><li>First set the axes for the left one <code>plt.axes([0.05, 0.05, 0.425, 0.9])</code> </li><li>Then plot the left graph <code>plt.plot(year, physical_sciences, color=&#x27;blue&#x27;)</code></li><li>The set the axes for the right one <code>plt.axes([0.525, 0.05, 0.425, 0.9])</code></li><li>and plot that graph <code>plt.plot(year, computer_science, color=&#x27;red&#x27;)</code></li></ul></li></ul></li></ul></li></ul></li><li><p>Plot graph in active subplot:</p><ul><li><strong>Plot line</strong>:</li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">plt.plot(</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    OPTION 1 WITH TWO LISTS: x_positions_of_points, y_positions_of_points, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    OPTION 2 WITH 1 DATAFRAME: dataframe_of_x_and_y </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    color=&#x27;blue&#x27;, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    label=str     # Used to label the line in the legend</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li><strong>Scatter</strong>: <code>plt.scatter(x_data, y_data, label=&#x27;data&#x27;, color=&#x27;red&#x27;, marker=&#x27;o&#x27;)</code></li><li><strong>Histogram</strong>: </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">plt.hist(pixels, bins=64, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    range=(0, 256),   # x-axis range</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    normed=True,      # normalized histogram</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    cumulative=True,  # cumulative density function instead of probability density function</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    color=&#x27;red&#x27;, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    alpha=0.4,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Alternatively</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">dataframe.hist()</span></div></div></div></div></div><ul><li><strong>Boxplot</strong>: <code>dataframe.boxplot(column = [y_axis_col_values], by=[x_axis_col_values])</code></li><li><strong>Add title</strong>: <code>plt.title(str)</code></li><li><strong>Change x and y labels</strong>: <code>plt.xlabel(str)</code> and <code>plt.ylabel(str)</code></li><li><strong>Change x and y limits (set range)</strong>: <code>plt.xlim(lower,upper)</code> and <code>plt.ylim(lower,upper)</code><ul><li>Inclusive</li><li><strong>Change both at the same time</strong>: <code>plt.axis((x_lower,x_upper,y_lower, y_upper))</code></li></ul></li><li><strong>Configuring xticks / yticks</strong>: <code>plt.xticks(rotation=degs)</code> and <code>plt.yticks(rotation=degs)</code><ul><li>ticks: the markers showing the coordinates on the x and y axis</li><li>rotation: angle at which ticks are displayed</li></ul></li></ul></li><li><p><strong>Add legend</strong>: <code>plt.legend(loc=&#x27;lower center&#x27;)</code></p></li><li><p><strong>Overlay plots</strong>: <code>plt.twinx()</code></p><ul><li>Use plt.twinx() to overlay plots with different vertical scales on a common horizontal axis.</li></ul></li><li><p><strong>Annotate</strong></p><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">plt.annotate(text, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    xy=(x_pos, y_pos),    # xy of value you&#x27;re pointing to</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    xytext=(x_pos, y_pos), </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    arrowprops=dict(facecolor=&#x27;black&#x27;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div></li><li><p><strong>2D histogram</strong>:</p><ul><li><code>plt.hist2d(horizontal_data, vertical_data, bins=(x_cols, y_rows), range=((x_min, x_max), (y_min, y_max)))</code></li><li>Range is optional</li><li>Instead of plotting the points directly on a graph, you turn it into something of a density map; the graph is split into a grid, and boxes with a lot of points will have a color of higher intensity.</li></ul></li><li><p><strong>2D hex histogram</strong>:</p><ul><li><code>plt.hexbin(horizontal_data, vertical_data, gridsize=(x_cols, y_rows), extent=(x_min, x_max, y_min, y_max))</code></li></ul></li><li><p><strong>Display points w/ color</strong>: <code>plt.pcolor(2D_arr,...)</code></p><ul><li>Add param <code>cmap=&#x27;Blues&#x27;</code> to config colormapping to Blues</li></ul></li><li><p><strong>Display color and intensity mapping</strong>: <code>plt.colorbar()</code></p><ul><li>Note that the bottom left part of the image maps to the top left part of the numpy array</li></ul></li><li><p><strong>Display points as contours</strong>: <code>plt.contour(X, Y, Z, contour_count, cmap=&#x27;color_map&#x27;)</code></p><ul><li>Filled: <code>plt.contourf(...)</code></li><li><a href="https://jakevdp.github.io/PythonDataScienceHandbook/04.04-density-and-contour-plots.html" target="_blank" rel="noopener noreferrer">See</a></li></ul></li></ul></li><li><p>Images</p><ul><li><strong>Load image</strong>: <code>npRGB = plt.imread(filepath)</code></li><li><strong>Display image</strong>: </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">plt.imshow(npRGB,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    cmap=&#x27;gray&#x27;,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    extent=(-1, 1, -1, 1) # horizontal extent from -1 to 1, vertical extent from -1 to 1</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    aspect=1              # aspect ratio (# of vertical pixels : # of horizontal pixels). </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                          # \lt 1 means img is squashed downwards; \gt 1 means img is stretched upwards</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li>Add cmap if only 1 channel</li><li><strong>RGB to monochannel</strong>: <code>npRGB.sum(axis=2)</code></li><li>Others:<ul><li><strong>Split RGB into channels:</strong><ul><li><code>red, green, blue = img[:,:,0], img[:,:,1], img[:,:,2]</code></li><li><strong>Flatten monochannel image (without modifying values) into 1-D array</strong>: <code>image.flatten()</code></li></ul></li><li>Normalize intensity:<ul><li><code>256*(img-img.min())/(img.max()-img.min())</code></li></ul></li></ul></li></ul></li><li><p>Export:</p><ul><li><strong>Show on GUI</strong>: <code>plt.show()</code></li><li><strong>Save to file</strong>: <code>plt.savefig(filepath)</code></li></ul></li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="seaborn-graphs"></a>Seaborn (Graphs)<a aria-hidden="true" tabindex="-1" class="hash-link" href="#seaborn-graphs" title="Direct link to heading">#</a></h3><p><code>import seaborn as sns</code></p><ul><li><p><strong>Simple linear regression</strong>:</p><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">sns.lmplot(x=&#x27;x_pos_col_in_df&#x27;, y=&#x27;y_pos_col_in_df&#x27;, data=dataframe</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    hue=&#x27;categorical_col_in_df&#x27;, # This col is categorical; will be used to group the points by colour</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    row=&#x27;groupby_row_wise&#x27;</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    palette=&#x27;Set1&#x27;</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li>straight line best fit</li><li>hue: e.g. you have a col &quot;gender&quot; that allows only {&#x27;M&#x27;,&#x27;F&#x27;}. <ul><li>Graph will color points that have value &#x27;M&#x27; to one color, and &#x27;F&#x27; to another color (i.e. groupby)</li></ul></li><li>row: same purpose as hue, but groupby row-wise<ul><li>i.e. Segregate points by each category and plot a separate graph for each</li></ul></li><li>plots on current plt graph. Use <code>plt.show()</code> to show </li></ul></li><li><p><strong>2nd order regression</strong>: </p><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">sns.regplot(x=&#x27;x_col_in_df&#x27;, y=&#x27;y_col_in_df&#x27;, data=dataframe,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    color=&#x27;green&#x27;, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    scatter=None,         # Set scatter to None if you don&#x27;t want to plot the scatter points; else ignore this line</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    order=2,              # 1 for simple lin. regr., 2 for 2nd order etc</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    label=&#x27;legend_label&#x27;  # label for legend</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li>curved line best fit</li><li></li></ul></li><li><p><strong>Residual plot</strong>: <code>sns.residplot(x=&#x27;x_col_in_df&#x27;, y=&#x27;y_col_in_df&#x27;, data=dataframe, color=color_str)</code></p><ul><li>Visualize how far datapoints diverge from the regression line.</li></ul></li><li><p><strong>Strip plot</strong>: A scatter plot where the x axis represents a categorical variable.</p><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">sns.stripplot(x=&#x27;x_col_in_df&#x27;, y=&#x27;y_col_in_df&#x27;, data=df,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    size = n,   # Size of dots</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    jitter=True # Useful when many points overlap, easier to see distribution. </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li><a href="https://seaborn.pydata.org/generated/seaborn.stripplot.html" target="_blank" rel="noopener noreferrer">Documentation</a></li></ul></li><li><p><strong>Swarm plot</strong>: Similar to strip plot, but the points visually spread out to avoid overlap</p><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">sns.swarmplot(x=&#x27;x_col_in_df&#x27;, y=&#x27;y_col_in_df&#x27;, data=df,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    orient = &#x27;h&#x27;/&#x27;v&#x27;  # h: y is now the categorical var. v: same as stripplot</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    size = n,         # Size of dots</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    hue=&#x27;col&#x27;,        # Categorical column to colour points by</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div></li><li><p><strong>Violin plot</strong>: Similar to a box plot, with the addition of a rotated kernel density plot on each side</p><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">sns.violinplot(x=&#x27;x_col_in_df&#x27;, y=&#x27;y_col_in_df&#x27;, data=df,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    color=&#x27;lightgray&#x27;,  # If you want all violins to be of the same color</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    inner=None          # Points are visualized in the center of each x coord. inner=None to only show the violin body.</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div></li><li><p><strong>Joint plot</strong>: Main plot in the middle defined by <code>kind</code>, combined with histograms aligned to the x and y axis at the side.</p><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">sns.jointplot(x=&#x27;hp&#x27;, y=&#x27;mpg&#x27;,data=auto,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    kind = &#x27;scatter&#x27; | &#x27;reg&#x27; | &#x27;resid&#x27; | &#x27;kde&#x27; | &#x27;hex&#x27;</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li>kind=&#x27;scatter&#x27;: scatter plot of the data points</li><li>kind=&#x27;reg&#x27;: regression plot (default order 1)</li><li>kind=&#x27;resid&#x27;: residual plot</li><li>kind=&#x27;kde&#x27;: kernel density estimate of the joint distribution</li><li>kind=&#x27;hex&#x27;: hexbin plot of the joint distribution</li></ul></li><li><p><strong>Pair(wise) plot</strong>: Take every pairwise combination of every non-categorical column in dataframe and plot main plot + histogram.</p><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">sns.pairplot(df, kind = &#x27;scatter&#x27; | &#x27;reg&#x27; | &#x27;resid&#x27; | &#x27;kde&#x27; | &#x27;hex&#x27;</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    hue = &#x27;categorical_col&#x27; # Categorical column to colour points by</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)```</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div></div></div></div></div></li><li><p><strong>Heatmap</strong>: Good for visualizing 2D arrays (e.g. covariance matrices)</p><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">sns.heatmap(df)</span></div></div></div></div></div></li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="scikit-learn"></a>scikit-learn<a aria-hidden="true" tabindex="-1" class="hash-link" href="#scikit-learn" title="Direct link to heading">#</a></h3><p><code>import sklearn</code>
<strong>train_test_split</strong></p><ul><li><code>from sklearn.model_selection import train_test_split</code></li><li>Use stratified sampling to split up the dataset according to the categorical_y_data dataset<ul><li><code>X_train, X_test, y_train, y_test = train_test_split(data_x, categorical_y_data, stratify=categorical_y_data)</code></li><li>Stratified: Make the distribution of each feature as close as possible to the original in the training and test sets</li><li>75% into training set and 25% into test set</li></ul></li></ul><p><strong>Concepts</strong></p><p>Data Standardization (normalization):</p><ul><li>Preprocessing task performed on numerical, continuous data to <strong>make it normally distributed</strong>. Standardize (assuming linear space) when:<ul><li><ol><li>Using a model that is in a linear space (any kind of model that uses a linear distance metric or operates in a linear space like k-nearest neighbors, linear regression, or k-means clustering). The model is assuming that the data and features you&#x27;re giving it are related in a linear fashion, or can be measured with a linear distance metric. </li></ol></li><li><ol start="2"><li>When a feature or features in your dataset have high variance ; if a feature in your dataset has a variance that&#x27;s an order of magnitude or more greater than the other features, this could impact the model&#x27;s ability to learn from other features in the dataset. </li></ol></li><li><ol start="3"><li>When features are of different scales e.g. height &amp; weight. To compare these features, they must be in the same linear space, and therefore must be standardized in some way. </li></ol></li></ul></li><li><strong>StandardScaler</strong>: For Data Standardization<ul><li>Finds mean and centers data around it (no limit to max / min)</li><li><strong>Import</strong>: <code>from sklearn.preprocessing import StandardScaler</code></li><li><strong>Creation</strong>: <code>ss = StandardScaler()</code></li><li><strong>Fit</strong>: <code>ss.fit(training_df_column)</code> (Call before transform)<ul><li>only fit with training data to avoid data leakage (won&#x27;t have access to test data)</li></ul></li><li><strong>Normalize scale</strong>: <code>ss.transform(dataframe_subset (columns))</code><ul><li>transform training data</li><li>Use <code>.fit_transform(...)</code> to fit, then transform data</li></ul></li></ul></li><li><strong>MinMaxScaling</strong>: For normalizing linear values to 0-1 by squashing min and max range to 0-1<ul><li>Use only when you know your data has a strict lower and upper bound</li><li><strong>Import</strong>: <code>from sklearn.preprocessing import MinMaxScaler</code></li><li><strong>Creation</strong>: <code>MM_scaler = MinMaxScaler()</code></li><li><strong>Fit</strong>: <code>MM_scaler.fit(training_df_column)</code> (Call before transform)<ul><li>only fit with training data</li></ul></li><li><strong>Transform</strong>: <code>resultantCol = MM_scaler.transform(training_df_column)</code><ul><li>transform training data</li><li>Use <code>.fit_transform(...)</code> to fit, then transform data</li></ul></li></ul></li><li><strong>Log transform</strong>: <ul><li><strong>Import</strong>: <code>from sklearn.preprocessing import PowerTransformer</code></li><li><strong>Creation</strong>: <code>pow_trans = PowerTransformer()</code></li><li><strong>Fit</strong>: <code>pow_trans.fit(training_df_column)</code> (Call before transform)<ul><li>only fit with training data</li></ul></li><li><strong>Normalize scale</strong>: <code>pow_trans.transform(dataframe_subset (columns))</code><ul><li>transform training data</li><li>Use <code>.fit_transform(...)</code> to fit, then transform data</li></ul></li></ul></li></ul><p>Data Sanitization</p><ul><li>Outlier Removal<ul><li>Quantile (percentage) based<ul><li><ol><li>Find quantile: <code>quantile = dataframe[&#x27;col&#x27;].quantile(0.95)</code></li></ol></li><li><ol start="2"><li>Trim: <code>trimmed_df = dataframe[dataframe[&#x27;col&#x27;] &lt; quantile]</code></li></ol></li></ul></li><li>standard dev based<ul><li>Get mean and std dev</li><li>Calculate cutoff e.g. <code>3 * std</code>, and lower (<code>mean - cutoff</code>) + upper (<code>mean + cutoff</code>) bounds</li><li>Trim outliers <code>df[(df[&#x27;col&#x27;] &lt; upper) &amp; (df[&#x27;col&#x27;] &gt; lower)]</code></li></ul></li></ul></li><li>Text preprocessing tricks<ul><li>Trim whitespace</li><li>Remove punctuation</li><li>Remove commonly occurring words or stopwords</li><li>Expanding contracted words (e.g. can&#x27;t)</li><li>Remove special characters such as numbers and emojis.</li><li>Done using <strong>tokenization</strong> (split corpus by space)</li><li>Done by <strong>lemmatization</strong> (convert word into base form e.g. &quot;eating&quot; &quot;ate&quot; into &quot;eat&quot;)</li></ul></li></ul><p>Feature Engineering</p><ul><li><p>Descript: Creation of new features from existing features (e.g. string/timestamp subsetting, aggregate numeric data across columns etc)</p></li><li><p><strong>LabelEncoder</strong>: Converting labelled column into {0,1} column</p><ul><li><strong>Creation</strong>: <code>enc = LabelEncoder()</code></li><li><strong>Encode as binary</strong>: <code>new_col = enc.fit_transform(dataframe[&#x27;col&#x27;])</code></li></ul></li><li><p><strong>One Hot Encoding</strong>: Convert column of categories into 2D binary array</p><ul><li>Do this instead of mapping categories to numbers, to avoid encoding ordering to the categories</li></ul></li><li><p><strong>Dummy Encoding</strong>: Same as one-hot encoding, but the first column dropped. Membership to the first column is indicated (implied) when all OHE are set to 0.</p><ul><li><strong>Both OHE &amp; Dummy use the same command:</strong></li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">pd.get_dummies(dataframe,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    columns = [column_labels], </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    drop_first=True, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    prefix=&#x27;col_prefix&#x27;</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div></li><li><p><strong>CountVectorizer</strong>: Vectorize text with word count</p><ul><li>Bag of words (BoW): Given a vocabulary e.g. [&#x27;a&#x27;,&#x27;sock&#x27;,&#x27;dog&#x27;], convert corpus into a dictionary counting number of times the words occur e.g. [0, 2, 1]</li><li><strong>Import</strong>: <code>from sklearn.feature_extraction.text import CountVectorizer</code></li><li><strong>Creation</strong>: </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">cv = CountVectorizer(</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    lowercase = bool,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    stop_words = &#x27;english&#x27; # optional for excluding stop words in the BoW vector</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    min_df: 0-1,   # Use only words that occur in more than this percentage of documents. This can be used to remove outlier words that will not generalize across texts.</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    max_df: 0-1,   # Use only words that occur in less than this percentage of documents. This is useful to eliminate very common words that occur in every corpus without adding value such as &quot;and&quot; or &quot;the&quot;.</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li><strong>Fit</strong>: <code>cv.fit(speech_df[&#x27;text_clean&#x27;])</code></li><li><strong>Get word list</strong>: <code>cv.get_feature_names()</code> </li><li><strong>Transform</strong>: <code>cv_transformed = cv.transform(speech_df[&#x27;text_clean&#x27;])</code><ul><li>returns sparse array</li><li><strong>To array</strong>: <code>cv_transformed.toarray()</code><ul><li>1 row per block of text and a column for each of the features generated by the vectorizer</li></ul></li></ul></li></ul></li><li><p><strong>tf-idf</strong>: Term Frequency - Inverse Document Frequency vector</p><ul><li>Descript: Text vectorization converts text to numerical input</li><li>[(# of word occurences) / (total words in document)] / log(# of docs word is in / total number of docs)<ul><li>Divide proportion of word occurence by proportion that it appears in all documents<ul><li>reduces value of common words</li></ul></li></ul></li><li><strong>Import</strong>: <code>from sklearn.feature_extraction.text import TfidfVectorizer</code></li><li><strong>Creation</strong>: </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">tfidf_vec = TfidfVectorizer(</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">  max_features=n, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">  stop_words=&#x27;english&#x27;,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">  ngram_range = (start, stop) # Adding some ordering. bi-gram (&quot;not happy&quot;) tri-gram (&quot;never not happy&quot;). Tries to fix bag of words problem</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li><p>stop_words will remove common words like &#x27;the&#x27;</p></li><li><p><strong>Transform</strong>: <code>text_tfidf = tfidf_vec.fit_transform(title_text)</code></p><ul><li>returns sparse array</li><li><strong>To array</strong>: <code>cv_transformed.toarray()</code></li><li>Indices and weights will be stored in the tfidf vector <code>text_tfidf</code></li><li>Vocabulary and weights will be stored in the TfidfVectorizer <code>tfidf_vec</code>.</li><li>Example</li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Instantiate TfidfVectorizer</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">tv = TfidfVectorizer(max_features=100, stop_words=&#x27;english&#x27;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Fit the vectroizer and transform the data</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">tv_transformed = tv.fit_transform(train_speech_df[&#x27;text_clean&#x27;])</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Transform test data</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">test_tv_transformed = tv.transform(test_speech_df[&#x27;text_clean&#x27;])</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Create new features for the test set</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">test_tv_df = pd.DataFrame(test_tv_transformed.toarray(), </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                          columns=tv.get_feature_names()).add_prefix(&#x27;TFIDF_&#x27;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">print(test_tv_df.head())</span></div></div></div></div></div><ul><li><strong>Get word list</strong>: <code>cv.get_feature_names()</code> </li><li><strong>Get word to index map</strong>: <code>str_idx_map = tfidf_vec.vocabulary_</code><ul><li><strong>Get index to word map</strong>: <code>idx_str_map = {v:k for k,v in tfidf_vec.vocabulary_.items()}</code></li></ul></li><li><strong>Get weights for every word in row</strong>: <code>text_tfidf[row_index].data</code><ul><li>If row_index is not number, use <code>iloc[n]</code></li></ul></li><li><strong>Get indices for every word in row</strong>: <code>text_tfidf[row_index].indices</code><ul><li><strong>Get indices to weights map for row</strong>: <code>idx_wgts_map = dict( zip(text_tfidf[row_index].indices, text_tfidf[row_index].data)</code><ul><li><strong>Get word to weights map for row</strong>: <code>str_wgts_map = {idx_str_map[i]:idx_wgts_map[i] for i in text_tfidf[row_index].indices}</code></li></ul></li></ul></li><li><strong>Get indices of top n weights</strong>: <code>top_n_idx = pd.Series(str_wgts_map).sort_values(ascending=False)[:top_n].index</code></li><li><strong>Get words of top n weights</strong>: <code>top_n_str = [idx_str_map[i] for i in top_n_idx]</code></li></ul></li></ul></li></ul><p>Feature Selection</p><ul><li>Removing <strong>redundant</strong> (noisy|correlated|duplicated) features.<ul><li>e.g. features that generated an aggregate statistic</li></ul></li></ul><p>Feature Extraction</p><ul><li>Transform data into new features</li><li><strong>Dimensionality Reduction</strong>: Reduce feature space<ul><li>Turning numericals into binned vals / binary</li><li><strong>Principle Component Analysis (PCA)</strong>: linear transformation to uncorrelated space<ul><li>Variance captured in a meaningful way by combining features into components</li><li>Number of components = number of input features</li><li>Difficult to interpret components, should be left to the end-of-preprocessing journey</li><li><strong>Creation</strong>: <code>pca = PCA()</code></li><li><strong>Transform</strong>: <code>transformed_X = pca.fit_transform(dataframe_X)</code><ul><li><strong>How much variance is explained by each component</strong>: <code>pca.explained_variance_ratio_</code></li></ul></li></ul></li></ul></li><li>POS tagging (Parts of Speech) (e.g. Pronoun, verb, article, noun)</li><li>Named Entity Recognition (NER) (e.g. Person, Organization)</li></ul><p>Models</p><p><strong>K-Nearest Neighbour (KNN)</strong> Classifier. <a href="https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn" target="_blank" rel="noopener noreferrer">See</a></p><ul><li>Return label of closest neighbour as prediction</li><li><strong>Import</strong>: <code>from sklearn.neighbors import KNeighborsClassifier</code></li><li><strong>Create</strong>: <code>knn = KNeighborsClassifier(n_neighbors=3)</code></li><li><strong>Training</strong>: <code>knn.fit(X_train (features), y_train (labels))</code></li><li><strong>Scoring</strong>: <code>knn.score(X_test, y_test)</code></li><li><strong>Predict</strong>: <code>predicted = knn.predict(input)</code></li></ul><p><strong>Naive Bayes</strong> Classifier: </p><ul><li>Assumes features are independent, works well with high-dimensional text data</li><li><strong>Training</strong>: <code>nb.fit(X_train (features), y_train (labels))</code></li><li><strong>Scoring</strong>: <code>nb.score(X_test, y_test)</code></li><li><strong>Predict</strong>: <code>predicted = nb.predict(input)</code></li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="numpy"></a>Numpy<a aria-hidden="true" tabindex="-1" class="hash-link" href="#numpy" title="Direct link to heading">#</a></h2><ul><li><strong>Import</strong>: <code>import numpy as np</code></li><li><strong>Numpy Array</strong><ul><li>Creation<ul><li><strong>Create array</strong>: <code>np.array(list)</code></li></ul></li><li>Attributes<ul><li><strong>Shape</strong>: <code>np_list.shape</code></li></ul></li><li>Unary Operations<ul><li><strong>Transpose array</strong>: <code>np.transpose(list)</code></li><li><strong>Reshape</strong>: <code>np.reshape(np_array, (new, shape, dimensions))</code>. <a href="https://numpy.org/doc/stable/reference/generated/numpy.reshape.html" target="_blank" rel="noopener noreferrer">Doc</a></li></ul></li><li>Operation with scalar<ul><li><strong>Slicing 2D numpy array (get row / get col)</strong>: <code>np_2d[row,:]</code>, <code>np_2d[:,col]</code></li><li><strong>Mass multiplication</strong>: <code>np_list *= val</code></li><li><strong>Iterate 2D array as 1D</strong>: <code>for x in np.nditer(np_2d_arr)</code></li></ul></li><li>Operations involving two numpy arrays<ul><li><strong>Mass operation</strong>: <code>np_list3 = np_list1 / np_list2</code></li><li><strong>Union</strong>: <code>np.logical_and(arr1, arr2)</code></li><li><strong>Intersect</strong>: <code>np.logical_or(a1,a2)</code><strong>* Negation of numpy arr</strong>: <code>np.logical_not(a1,a2)</code></li></ul></li><li>Operations involving boolean arrays<ul><li><strong>Generate boolean array by applying condition to array</strong>: <code>bool_val = np_list &gt; val</code></li><li><strong>Subsetting with bool array</strong>: <code>np_list[bool_val]</code></li></ul></li><li>Aggregation Operations<ul><li><strong>Mean</strong>: <code>np.mean(np_list)</code></li><li><strong>Median</strong>: <code>np.median(np_list)</code></li><li><strong>Std Dev</strong>: <code>np.std(np_list)</code></li><li><strong>Variance</strong>: <code>np.var(np_list)</code></li><li><strong>Correlation Coeff</strong>: <code>np.corrcef(np_list1, np_list2)</code></li></ul></li></ul></li><li><strong>Numpy Random</strong><ul><li><strong>Init with Seed</strong>: <code>np.random.seed(seed)</code></li><li><strong>Generate Float</strong> 0-1: <code> np.random.rand()</code></li><li><strong>Generate Integer</strong>: <code>np.random.randint(lowerIncl, upperExcl)</code></li></ul></li><li><strong>Definitions</strong><ul><li><strong>NaN</strong>: <code>np.nan</code></li></ul></li><li><strong>Operations</strong><ul><li><strong>Log10</strong>: <code>np.log10(nd_arr or dataframe)</code></li><li><strong>1D interpolation</strong>: <a href="https://numpy.org/doc/stable/reference/generated/numpy.interp.html" target="_blank" rel="noopener noreferrer">doc</a></li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">np.interp(xcoords_to_interpolate, data_xcoords, data_ycoords, left=None, right=None, period=None)</span></div></div></div></div></div></li><li><strong>Generate uniformly spaced list</strong>: <code>np.linspace(lower_lim, upper_lim, number_of_items)</code></li><li><strong>Meshgrid: create a grid by using coordinates of each dimension</strong>: <code>np.meshgrid(columns, rows)</code><ul><li><a href="https://stackoverflow.com/a/42404323" target="_blank" rel="noopener noreferrer">See</a></li></ul></li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="pandas"></a>Pandas<a aria-hidden="true" tabindex="-1" class="hash-link" href="#pandas" title="Direct link to heading">#</a></h2><ul><li><strong>Import</strong>: <code>import pandas as pd</code></li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="series-pandas-labelled-list"></a>Series (Pandas labelled list)<a aria-hidden="true" tabindex="-1" class="hash-link" href="#series-pandas-labelled-list" title="Direct link to heading">#</a></h4><ul><li><strong>From list</strong>: <code>pd.Series(array, ..., index=arr)</code></li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="dataframe-pandas-labelled-excel-sheets--dictionaries"></a>DataFrame (Pandas labelled excel sheets / dictionaries)<a aria-hidden="true" tabindex="-1" class="hash-link" href="#dataframe-pandas-labelled-excel-sheets--dictionaries" title="Direct link to heading">#</a></h4><p>Creation / Conversion</p><ul><li><p><strong>From Dictionary</strong>: <code>pd.DataFrame(dict)</code></p></li><li><p><strong>From CSV File</strong>: </p><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">dataframe = pd.read_csv(string_filename, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    delimiter   = str,          # The shorthand &#x27;sep&#x27; serves the same purpose</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    header      = line_no_start_of_data, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    index_col   = i, # Column to use as row labels of the df. Set to False to force pandas not to use the first column as the index, or to a col name if you want to use that col</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    [chunksize   = n, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    names       = new_col_labels_list, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    comment     = str_prefix, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    parse_dates = [date_col...]</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li>Note that dataframes are iterables, so you can use &quot;next(iterable)&quot; on them (to get them in the chunksize)</li></ul></li><li><p><strong>Converting to set</strong>: <code>set(df[&#x27;col&#x27;])</code></p></li><li><p><strong>add_prefix to all cols</strong>: <code>df.add_prefix(str)</code></p></li></ul><p>Accessing / Selection</p><ul><li><strong>For Loop for each row</strong> (note that row is a dataframe / dictionary)<ul><li><code>for idx, row in df.iterrows(): ...</code></li></ul></li><li>Slicing<ul><li><strong>Get column as Series</strong>: <code>dataframe[&quot;column&quot;]</code><ul><li><strong>Convert series to numpy.ndarray</strong>: <code>series.values</code></li></ul></li><li><strong>Extract columns from DF</strong>: <code>dataframe[[&quot;column&quot;,...]]</code><ul><li><strong>Dataframe as rows</strong>: <code>dataframe[startIdxIncl: endIdxExcl]</code></li></ul></li></ul></li><li>Array based selection<ul><li><strong>Select by label</strong>: <ul><li><code>dataframe.loc[label]</code> (transposed / series / numpy array)</li><li><code>dataframe.loc[[rowLbl1, rowLbl2..* .],[colLbl1, colLbl2...]]</code> (tabular / dataframe)</li><li><strong>Select by index, not name</strong>: Replace loc with iloc<ul><li><code>df.iloc[&lt;slicing for row&gt;, &lt;slicing for column&gt;]</code></li></ul></li><li><strong>Select all rows by column</strong>: Replace label with &#x27;:&#x27; <ul><li><code>dataframe.loc[&lt;slicing for row&gt;, &lt;slicing for column&gt;]</code></li><li><code>dataframe.loc[:,col]</code> (Returns numpy array)</li><li><code>dataframe.loc[:,* [cols]]</code> (Returns Dataframe)</li></ul></li><li><strong>MultiIndexes</strong>: <code>df.loc[(top_lvl_idx,2nd_lvl_idx,...), &lt;slicing for column&gt;]</code><ul><li>e.g. <code>sales.loc[(&#x27;NY&#x27;,1),:], sales.loc[(slice(None),2),:]</code></li><li>If you have to use <code>:</code> for slicing, replace the tuple with <code>pd.IndexSlice[top_lvl_idx,2nd_lvl_idx,...]</code><ul><li>e.g. <code>df.loc[pd.IndexSlice[:,2nd_lvl_idx,...], &lt;slicing for column&gt;]</code></li><li><em>Datacamp loves to create the alias <code>idx=pd.IndexSlice</code> to shorten the .loc call.</em></li></ul></li><li>MultiIndexes: the index is an array instead of a single value (think of nested arrays. e.g. arr[1][2], MultiIndex would be (1,2) or something)</li></ul></li><li><strong>By Datetime</strong> (if index is datetime): <code>ts0.loc[&#x27;2010-August&#x27;:&#x27;2010-10-11 22:00:00&#x27;]</code> <ul><li><em>can even be like &#x27;2010-Aug&#x27;</em></li></ul></li><li>(See more: <a href="https://www.w3resource.com/pandas/dataframe/dataframe-loc.php" target="_blank" rel="noopener noreferrer">https://www.w3resource.com/pandas/dataframe/dataframe-loc.php</a>)<ul><li>slicing refers to x[startðŸ”šstep].</li><li>Special slices:<ul><li>[:] =&gt; Select all</li><li>[n:] =&gt; from the nth element (inclusive) to the end; note that n starts from 0</li><li>[:n] =&gt; from the first element to the nth element</li></ul></li></ul></li></ul></li></ul></li><li>Conditional Select<ul><li><strong>Get by bool arr</strong>: <code>df[bool_arr]</code></li><li><strong>Get</strong>: <code>dataframe[dataframe[&quot;column&quot;] == condition]</code></li><li><strong>Assignment:</strong> <code>df.loc[df[&#x27;col&#x27;] &lt;condition&gt;, &#x27;column_to_set&#x27;] = value_to_assign</code></li><li><strong>Multiple conditional</strong>: <code>(df[&#x27;col&#x27;] == condition) &amp; (df[&#x27;col&#x27;] == condition)</code></li><li><code>dataframe[&quot;col&quot;] = dataframe[&#x27;col&#x27;] == condition</code></li><li><strong>By data type</strong>: <code>df.select_dtypes(include=[int, float])</code></li></ul></li><li><strong>Get data as datetime</strong>: <code>df[&#x27;col&#x27;].dt</code><ul><li><strong>Format datetime</strong>: <code>df[&#x27;col&#x27;].dt.strftime(&#x27;formatstr&#x27;)</code><ul><li>formatstr: e.g. &#x27;%Y&#x27; to only get the year</li></ul></li></ul></li><li><strong>Get data as str</strong>: <code>df[&#x27;col&#x27;] = df[&#x27;col&#x27;].str</code><ul><li><em>This can be combined by concatenating string functions behind e.g. .lower(), .strip(), .upper(), .replace(dict), .replace(&quot;old&quot;,&quot;new&quot;), .len()</em></li><li>Other fun obscure string functions include .startswith()</li><li>Chains must be prefixed with a <code>.str</code> in front e.g. `.str.replace(&#x27;x&#x27;,&#x27;&#x27;).str.replace(...)</li><li><em>Note that these string functions return a df, which can be combined with other str or aggregation functions</em></li><li><strong>Word count</strong>: <code>df[&#x27;col&#x27;].str.split().str.len()</code></li></ul></li></ul><p>Data Addition</p><ul><li>New Column:<ul><li><strong>Add new value</strong>: <code>df.loc[lbl, col] = val</code> (do this for every row to add the column)</li><li><strong>Set column to that value for every row</strong>: <code>df[&#x27;col&#x27;] = val</code></li><li><strong>Modify by transformation function</strong>: <code>df[&quot;newCol&quot;] = df[&quot;oldCol&quot;].apply(transformFx)</code><ul><li>e.g. <code>df.apply(lambda row: row.mean(), axis=1)</code></li><li>Regex can also be used etc</li></ul></li><li><strong>Modify by mapping values to a dictionary</strong>: <code>df[&#x27;col&#x27;].map(dict_map_vals)</code></li></ul></li><li>New Row:<ul><li><strong>Append dataframe</strong>: </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">df1.append(df2,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    ignore_index=False | True # False: Preserve index. True: Number everything from 0 to n</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div></li><li><strong>Concatenating / Joining list of series/dataframes</strong>: <ul><li><strong>Plus</strong> (if indexes are properly set): <code>df1 + df2</code></li><li><strong>Concat</strong><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">pd.concat(list_of_dataframes, # Concatenating a dictionary will result in the keys becoming the indexes</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    axis=&#x27;index&#x27; | &#x27;columns&#x27;, # &#x27;index&#x27;: Stack below (&quot;vertically&quot;), &#x27;columns&#x27;: Stack to the right (&quot;horizontally&quot;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    keys=[&#x27;one&#x27;,&#x27;col&#x27;,&#x27;name&#x27;,&#x27;per&#x27;,&#x27;dataframe&#x27;,&#x27;in&#x27;,&#x27;list&#x27;],</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    join=&#x27;inner&#x27;,     # optional, keep only rows that share common index labels.</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    ignore_index=bool # If True, prevents repeated integer indices</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div></li><li>Keys: 1 key per DataFrame in the list, forming the outer index in the MultiIndex. The resulting DataFrame will be something like df[&#x27;one&#x27;][n] to access the first DataFrame, df[&#x27;col&#x27;][n] to access the 2nd DataFrame etc.</li><li><strong>Merge / Join</strong><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Inner join, Equivalent to pd.concat([leftDF, rightDF], &#x27;columns&#x27;, join=&#x27;inner&#x27;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">pd.merge(leftDF, rightDF, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    on=column_label, # See exposition below</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    how=&#x27;inner&#x27;,     # Type of join. See below</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    suffixes=[sfx_forDF1, sfx_forDF2] # If both DFs have columns of same name, add suffix at the end if not merging on those columns</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div></li><li><strong>on:</strong> If multiple columns form the identifier: use <code>on=[col1,col2,...]</code>. Otherwise, the join will horizontally append copies of the columns even if they are the same.</li><li><strong>on:</strong> If df1 and df2 use different labels for the same identifier, use <code>left_on</code> and <code>right_on</code>.</li><li><strong>how:</strong> You can also define various types of joins as specified <a href="https://mode.com/sql-tutorial/sql-outer-joins/" target="_blank" rel="noopener noreferrer">here</a> </li><li>See <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html" target="_blank" rel="noopener noreferrer">documentation</a> if need to be more specific</li><li><strong>Ordered merge</strong><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Same as pd.merge above, but designed for ordered data like time series and filling and interpolation.</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">pd.merge_ordered(leftDF, rightDF,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    fill_method=&quot;ffill&quot; # Forward-filling: Replace NaN entries with the most recent non-null entry,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    # Other params same as above)</span></div></div></div></div></div></li><li><strong>Merge with value comparison</strong><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">pd.merge_asof(...)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># pd.merge_asof() is like the pd.merge_ordered() function; it merges values in order using the on column</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># but for each row in the left DataFrame, only rows from the right DataFrame whose &#x27;on&#x27; column values are less than the left value will be kept.</span></div></div></div></div></div>Data Deletion</li></ul></li><li><strong>Drop rows / columns</strong>: </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">df.drop(labels,               # Index or column labels to drop. </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    axis= &#x27;index&#x27; | &#x27;columns&#x27;</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li><strong>Drop rows / columns with missing values</strong>: </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">df.dropna(</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    subset = [column_labels]    # Labels along other axis to consider, e.g. if you are dropping rows these would be a list of columns to include.</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    how = &#x27;any&#x27; | &#x27;all&#x27;         # &#x27;any&#x27; : If any NA values are present, drop that row or column. </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                                # &#x27;all&#x27; : If all values are NA, drop that row or column.</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    thresh = n                  # Drop unless there are at least n non-NA values along that axis</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    axis = &#x27;index&#x27; | &#x27;columns&#x27;  # 0/â€˜indexâ€™   : Drop rows    which contain missing values. </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                                # 1/â€˜columnsâ€™ : Drop columns which contain missing values.</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li>See <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html" target="_blank" rel="noopener noreferrer">documentation</a></li><li><strong>Drop duplicate rows</strong>: </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">df.drop_duplicates(</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    subset = arr_of_col_names, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    keep = &#x27;first&#x27; | &#x27;last&#x27; | False, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    inplace = bool</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><p>Value Modification</p><ul><li><strong>Dividing one DF by another</strong>:<div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">DF1.divide(DF2, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    axis=&#x27;rows&#x27;/&#x27;columns&#x27; # Divide the DF1 by DF2 along each row</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div></li></ul><p>Metadata modification</p><ul><li><strong>Re-labelling columns</strong>: <code>df.columns = arr_of_labels</code></li></ul><p>Datatype modification</p><ul><li><strong>Convert to datetime</strong>: </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">pd.to_datetime(df[&#x27;col&#x27;],</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    format = date_str_format,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    infer_datetime_format = True | False,  # Infer format based on first non-NaN element. Can increase parsing speed by 5-10x (disabled by default)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    errors = &#x27;raise&#x27; | &#x27;coerce&#x27; | &#x27;ignore&#x27; # raise = raise exception, coerce = set to NaT (not a time), ignore = ignore</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li>A datetime column will allow you to manipulate the datetime directly &amp; search for rows that match the date using df.loc<ul><li>You can also extract information from it using its attributes. See any attr under <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.month.html" target="_blank" rel="noopener noreferrer">pandas.Series.dt</a>.<ul><li><strong>Adding a new column for min/year etc</strong>: <code>df[&quot;month&quot;] = df[&quot;date&quot;].apply(lambda row: row.month)</code></li></ul></li></ul></li><li>Example of merging 2 string cols into 1 datetime: <code>times_tz_none = pd.to_datetime(la[&#x27;Date (MM/DD/YYYY)&#x27;] + &#x27; &#x27; + la[&#x27;Wheels-off Time&#x27;])</code></li><li><strong>Convert to numeric</strong>: <code>pd.to_numeric(df[&#x27;col&#x27;], errors=&#x27;coerce&#x27;)</code></li><li><strong>Convert to categorical</strong>: </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">df[&#x27;col&#x27;] = pd.Categorical(values=df[&#x27;col&#x27;], categories=arr_of_values, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    ordered=True # True: ordered categoricals</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li><strong>Bin values into discrete intervals (Convert numbers to categories)</strong>: </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">df[&#x27;col&#x27;] = pd.cut(df[&#x27;col&#x27;], </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    bins = arr_of_bin_edges,    # e.g. [0, 60, 180, np.inf]</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    labels = arr_of_categories  # e.g. [&#x27;short&#x27;, &#x27;medium&#x27;, &#x27;long&#x27;]</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"># Alternatively, if you just want to cut them into equal sized bins</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">df[&#x27;col&#x27;] = pd.cut(df[&#x27;col&#x27;], </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    bins = bin_counts</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li><strong>Convert to other types</strong>: <code>df[&#x27;newCol&#x27;] = df[&#x27;dataCol&#x27;].astype(&#x27;type&#x27;)</code></li></ul><p>Datetime timezone modification</p><ul><li><strong>Localizing timezone</strong>: <code>series.dt.tz_localize(&quot;US/Central&quot;)</code></li><li><strong>Converting timezone</strong>: <code>series.dt.tz_convert(&quot;US/Central&quot;)</code></li></ul><p>Operations that involve boolean arrays:</p><ul><li>Operations that convert DF into boolean DF:<ul><li><strong>Value meets condition</strong>: <code>df_bool_arr = df[&#x27;col&#x27;] &gt; val</code></li><li><strong>Value membership</strong>: <code>df[&#x27;col&#x27;].isin(arr_of_acceptable_values)</code></li><li><strong>Value is null or NA</strong>: <code>df.isnull()</code> or <code>df.isna()</code> (they are the same)</li><li><strong>Value is not null</strong>: <code>df.notnull()</code> or <code>df.notna()</code></li><li><strong>Row is duplicated</strong>: <code>df.duplicated(subset = arr_of_col_names, keep = &#x27;first&#x27; | &#x27;last&#x27; | False)</code></li></ul></li><li><strong>Negate boolean array</strong>: <code>~bool_arr</code></li><li><strong>Subsetting with bool array</strong>: <code>df[bool_df]</code></li></ul><p>Unary Operations</p><ul><li><strong>Compute % change from the immediate previous</strong>: <code>series.pct_change(offset=1)</code>: <ul><li>Row by default. Useful in comparing the percentage of change in a time series of elements. </li><li>Offset is in unit time specified in sample</li></ul></li></ul><p>Grouping Data</p><ul><li><strong>Downsample time series</strong>: <code>df[&#x27;col&#x27;].resample(time_str_format).agg_fx()</code><ul><li>e.g. <code>df.Temperature.resample(&#x27;6h&#x27;).mean()</code> = group an hourly based time series into averaged quarterly data</li><li><code>df.resample(&#x27;A&#x27;).mean()</code>: resample w/ annual frequency, assumes index is a datetime</li><li><code>df.resample(&#x27;A&#x27;, on=column_label).mean()</code>: resample w.r.t a column label that isn&#x27;t the index</li></ul></li><li><code>groupby</code> function:<ul><li><strong>Group-by (Single index)</strong>: <code>df.groupby(&#x27;idx&#x27;)</code></li><li><strong>Group-by (Multi-Index)</strong>: <code>df.groupby([indexes])</code></li><li><strong>Group-by (Rows)</strong>: <code>df.groupby(pd.Series([&#x27;row_vals&#x27;])</code></li><li>Note that the groupby function should be followed up with a column + aggregate for it to be useful, unless you want to literally count the number of rows etc<ul><li>e.g. count_by_class = by_class[&#x27;survived&#x27;].count()</li></ul></li><li>Group by Day example: <code>by_day = sales.groupby(sales.index.strftime(&#x27;%a&#x27;))</code></li><li><strong>Multiple Aggregation (columns)</strong>: <code>sales.groupby(&#x27;city&#x27;)[[&#x27;bread&#x27;,&#x27;butter&#x27;]].max()</code><ul><li><img src="/My-Docs/assets/images/groupby-max-be4dcc64d1a8ebef95937a4e84b1f704.jpg"></li></ul></li><li><strong>Multiple aggregation (functions)</strong>: <code>sales.groupby(&#x27;city&#x27;)[[&#x27;bread&#x27;,&#x27;butter&#x27;]].agg([&#x27;max&#x27;,&#x27;sum&#x27;])</code><ul><li><img src="/My-Docs/assets/images/groupby-max-sum-33ff5f981a0bb408858c107e9f564bd4.jpg"></li><li><strong>Custom aggregation (own function)</strong>: You can define a function that accepts a Series and returns a single value.</li><li><strong>Separate aggregation per column (dictionary)</strong>: You can define a dictionary and put it into .agg; the key is the column, the value is the aggregation function (e.g. max, min)</li><li><code>df.groupby(...).transform(fx)</code>: Transform after aggregation (group by, then transform values based on their groups)<ul><li>Output is the same shape as before groupby.</li><li>e.g. `def zscore(series): return (series - series.mean()) / series.std()</li><li>Usage: <code>df.groupby(&#x27;x&#x27;)[&#x27;y&#x27;].transform(zscore)</code></li></ul></li></ul></li></ul></li><li><strong>Filtering (after groupby)</strong>:<ul><li><code>by_company = sales.groupby(&quot;Company&quot;)</code></li><li><strong>Compute sum of &#x27;Units&#x27;</strong>: <code>by_com_sum = sales[&#x27;Units&#x27;].sum()</code></li><li><strong>Filter &#x27;Units&#x27; where sum &gt; 35</strong>: <code>by_com_filt = by_company.filter(lambda g:g[&#x27;Units&#x27;].sum() &gt; 35)</code></li></ul></li></ul><p>Aggregation Operations</p><ul><li><strong>Get Uniques</strong>: <code>df.unique()</code></li><li><strong>Aggregate duplicates</strong>: <code>df.groupby(by = arr_of_col_names).agg(col_to_fx_dict).reset_index()</code><ul><li><em>col_to_fx_dict</em>: e.g. {&#x27;height: &#x27;max&#x27;, &#x27;weight&#x27;: mean}</li></ul></li><li><strong>sum</strong>: <code>df[&#x27;col&#x27;].sum(axis={index (0), columns (1)})</code><ul><li><em>You can also sum booleans to count number of True values</em></li><li><strong>Count number of missing values by col</strong>: <code>df.isna().sum()</code></li></ul></li><li><strong>mean</strong>: <code>df[&#x27;col&#x27;].mean()</code></li><li><strong>max</strong>: <code>df[&#x27;col&#x27;].max()</code></li><li><strong>argmax</strong> (idx of max val): <code>df[&#x27;col&#x27;].argmax()</code></li><li><strong>count</strong>: <code>df[&#x27;col&#x27;].count()</code></li><li><strong>quantile</strong>: <code>quantile([start, end (0-1)])</code><ul><li>Get single value: <code>quantile(pct_from_0_to_1)</code></li></ul></li><li><strong>std.dev</strong>: <code>std()</code></li><li><strong>rolling mean</strong>: <code>df[&#x27;col&#x27;].rolling(window=numRows).mean()</code></li><li><strong># of uniques:</strong> <code>nunique()</code></li><li><strong>Count number of times value appeared</strong>: <code>value_counts()</code> / <code>series.value_counts()</code><ul><li>Returns dataframe (dictionary)
Sorting Operations</li></ul></li><li><strong>Sort by current index</strong>: <code>df.sort_index(level=idx_lvl)</code><ul><li>You may want to change the index by using <code>df.set_index()</code> first</li></ul></li><li><strong>Sort values by column name</strong>: <code>df.sort_values(by = arr_of_col_names)</code> or <code>df.sort_values(&#x27;col&#x27;)</code><ul><li><strong>Sort df chosen by boolean array</strong>: <code>df[bool_arr].sort_values(...)</code></li></ul></li></ul><p>Windowing Operations</p><ul><li><a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/computation.html" target="_blank" rel="noopener noreferrer">Documentation</a></li><li><code>df.expanding()</code><ul><li>See <a href="https://stackoverflow.com/questions/45370666/what-are-pandas-expanding-window-functions" target="_blank" rel="noopener noreferrer">this</a>: &quot;A common alternative to rolling statistics is to use an expanding window, which yields the value of the statistic with all the data available up to that point in time&quot;</li></ul></li></ul><p>Operations on Indexes:</p><ul><li><strong>Interpolate</strong>: <code>ts2_interp = ts2.reindex(ts1.index).interpolate(how=&#x27;linear&#x27;) </code><ul><li>in the above example, the index is changed to datetime. ts1 contains all datetime, ts2 has some missing data</li></ul></li><li><strong>Changing metadata / restructuring</strong><ul><li><strong>Reindex</strong> (Change values of the 1st column): <code>df = df.reindex(col/df2.index,[method=pad/backfill/nearest])</code><ul><li><em>Conform DataFrame to new index with optional filling logic, placing NA/NaN in locations having no value in the previous index. A new object is produced unless the new index is equivalent to the current one and copy=False</em></li></ul></li><li><strong>Change index entirely</strong>: <code>df.set_index(&#x27;colname&#x27;,inplace=bool)</code>. <ul><li>This is usually done as an interim operation to make naivgating the DF easier, or for using <code>sort_index()</code></li><li><a href="https://stackoverflow.com/questions/50741330/difference-between-df-reindex-and-df-set-index-methods-in-pandas" target="_blank" rel="noopener noreferrer">Reindex vs set_index</a></li></ul></li><li><strong>Reset index</strong>: <code>df.reset_index()</code></li></ul></li></ul><p>Operations on Restructuring Data (Pivoting)</p><ul><li><strong>Pivot (reorder data by changing the index, columns &amp; values. REQUIRES UNIQUE INDEX)</strong>: </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">df.pivot(</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    index=new_row_index,      # Each unique value in the column is now a primary key of the row. Aggfunc aggregates if there are duplicate PKs.</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    columns=new_columns,      # Each unique value in the column is now a column</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    values=old_cols_to_vals   # Each value in the column are now assigned to row-column where they occur. Aggregate if needed. </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li><strong>Pivot Table: Same as pivot, but deal with duplicate index values with a reduction using aggfunc</strong>:</li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">df.pivot_table(</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    index=new_row_index,        # Each unique value in the column is now a primary key of the row. Aggfunc aggregates if there are duplicate PKs.</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    columns=new_columns,        # Each unique value in the column is now a column</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    values=old_cols_to_vals     # Each value in the column are now assigned to row-column where they occur. Aggregate if needed. </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    aggfunc=fx/&#x27;predefined_fx&#x27;, # Aggregate duplicate index values using this function</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    margins=bool                # If True, add a &quot;All&quot; row at the bottom which aggregates all data</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li><strong>Melt: undoing a pivot</strong>: </li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">pd.melt(dataframe, </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    id_vars=[&#x27;cols&#x27;],               # column names to keep as columns</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    value_vars=[&#x27;cols&#x27;],            # column names to convert into key-value pairs, under two columns: </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                                    # 1st column specified as &quot;variable&quot; which uses the original column name</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    value_name=[&#x27;value_col_names&#x27;], # 2nd column whose name is specified by value_name</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    col_level = 0                   # use col_level = 0 to convert it into purely variable-value pair, removing any id_vars / indexes currently in use</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">)</span></div></div></div></div></div><ul><li><a href="https://pandas.pydata.org/docs/reference/api/pandas.melt.html" target="_blank" rel="noopener noreferrer">documentation</a></li><li><strong>Stack</strong>: <code>df.stack(level=&#x27;col&#x27;)</code><ul><li><a href="https://www.w3resource.com/pandas/dataframe/dataframe-stack.php" target="_blank" rel="noopener noreferrer">stack the prescribed level(s) by shifting columns to index</a></li></ul></li><li><strong>Unstacking</strong>: <code>df.unstack(level=&#x27;col&#x27;/num)</code><ul><li><a href="https://www.w3resource.com/pandas/dataframe/dataframe-unstack.php" target="_blank" rel="noopener noreferrer">form new level of columns whose inner-most level consists of the pivoted index labels</a></li></ul></li><li><strong>Swap level</strong>: <a href="https://www.geeksforgeeks.org/python-pandas-multiindex-swaplevel/" target="_blank" rel="noopener noreferrer">swap ordering of stacked levels</a></li></ul><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button tabindex="0" type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">dataframe.swaplevel(</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    index1_level, # e.g. 0 for the outer-most level</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    index2_level, # e.g. 1 for the inner level</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    axis=&#x27;index&#x27;|&#x27;columns&#x27;)</span></div></div></div></div></div><ul><li>Operations involving missing values and cleaning data:</li><li><strong>Impute/Replace missing vals</strong>: <code>df.fillna({&#x27;col&#x27; : val_arr}, inplace=True)</code><ul><li>See <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html?highlight=fillna#pandas.DataFrame.fillna" target="_blank" rel="noopener noreferrer">documentation</a></li></ul></li></ul><p>Operations involving visualization </p><ul><li>DataFrame Info<ul><li><strong>Correlation between columns</strong>: <code>df.corr()</code></li><li><strong>Display head</strong>: <code>df.head(&lt;rows=5&gt;)</code></li><li><strong>Display tail</strong>: <code>df.tail(&lt;rows=5&gt;)</code></li><li><strong>Display schema</strong>: <code>df.info()</code> (Shows col name, non-null entries &amp; datatype)<ul><li><strong>Display columns</strong>: <code>df.columns</code></li></ul></li><li><strong>Display summary stats (e.g. std,min,max,quartiles)</strong>: <code>df.describe()</code> (also works on columns of the df)</li><li><strong>Display datatype</strong>: <code>df.dtype</code> or <code>df.dtypes</code> (works on columns of the df)</li><li><strong>Size / Length / Shape</strong>: <code>df.shape</code></li></ul></li><li>Plotting data from DataFrame (See matplotlib.pyplot):<ul><li><code>dataframe.plot(kind=&#x27;scatter&#x27;, x=&#x27;col1&#x27;, y=&#x27;col2&#x27;, [color=&#x27;str&#x27;, s=size_value,subplots=bool])</code><ul><li>you can plot all data by omitting x and y</li><li>subplots: plot in separate graphs</li></ul></li><li><code>dataframe.boxplot(column = [y_axis_col_values], by=[x_axis_col_values])</code></li><li><code>ax = df[list_of_columns].plot() </code><ul><li>You can customize the plot by calling the functions below on ax:<ul><li><code>ax.set_ylabel(&quot;% Change of Host Country Medal Count&quot;)</code></li><li><code>ax.set_title(&quot;Is there a Host Country Advantage?&quot;)</code></li><li><code>ax.set_xticklabels(editions[&#x27;City&#x27;])</code></li></ul></li><li>plot all of the columns (their x and y) on the same graph with their own colours</li><li>plt.title(str)</li><li>plt.xlabel(str)</li><li>plt.ylabel(str)</li><li>plt.show()</li></ul></li><li>Subplots<ul><li><code>fig, axes = plt.subplots(nrows=num_of_rows, ncols=num_of_columns)</code></li><li><code>df.plot(ax=axes[0], kind=&#x27;hist&#x27;, normed=True, bins=30, range=(0,.3))</code></li><li><code>df.fraction.plot(ax=axes[1], kind=&#x27;hist&#x27;, normed=True, cumulative=True, bins=30, range=(0,.3))</code><ul><li><code>kind=&#x27;bar&#x27;</code></li></ul></li></ul></li></ul></li></ul></div></article><div class="margin-vert--xl"><div class="row"><div class="col"><a href="https://github.com/crazoter/My-Docs/edit/master/website/docs/markdown/python.md" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="1.2em" width="1.2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 40 40" style="margin-right:0.3em;vertical-align:sub"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></div><div class="margin-vert--lg"><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/My-Docs/docs/markdown/machine_learning"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« Machine Learning</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/My-Docs/docs/markdown/math"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Math Â»</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_3SO_"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#pure-python" class="table-of-contents__link">Pure Python</a></li><li><a href="#libraries--modules" class="table-of-contents__link">Libraries / Modules</a><ul><li><a href="#regex" class="table-of-contents__link">Regex</a></li><li><a href="#recordlinkage-join-datasets-wo-common-uid" class="table-of-contents__link">Recordlinkage (Join datasets w/o common UID)</a></li><li><a href="#fuzzywuzzy-string-comparison" class="table-of-contents__link">fuzzywuzzy (String Comparison)</a></li><li><a href="#missingno-visualize-missing-data" class="table-of-contents__link">missingno (Visualize missing data)</a></li><li><a href="#scipystats-zscore" class="table-of-contents__link">scipy.stats (zscore)</a></li><li><a href="#textatistic-evaluate-word-readability" class="table-of-contents__link">Textatistic (Evaluate word readability)</a></li><li><a href="#spacy-tokenization-and-lemmatization" class="table-of-contents__link">spacy (tokenization and lemmatization)</a></li><li><a href="#matplotlibpyplot-graphs--images" class="table-of-contents__link">matplotlib.pyplot (Graphs &amp; Images)</a></li><li><a href="#seaborn-graphs" class="table-of-contents__link">Seaborn (Graphs)</a></li><li><a href="#scikit-learn" class="table-of-contents__link">scikit-learn</a></li></ul></li><li><a href="#numpy" class="table-of-contents__link">Numpy</a></li><li><a href="#pandas" class="table-of-contents__link">Pandas</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><h4 class="footer__title">Links</h4><ul class="footer__items"><li class="footer__item"><a href="https://www.linkedin.com/in/matthew-lee-6a8a8a70/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn</a></li><li class="footer__item"><a href="https://crazoter.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">Portfolio</a></li></ul></div></div><div class="text--center"><div>Copyright Â© 2021 Matt's Docs, crazoter. Built with Docusaurus.</div></div></div></footer></div>
<script src="/My-Docs/styles.e0990858.js"></script>
<script src="/My-Docs/runtime~main.b515bb10.js"></script>
<script src="/My-Docs/main.11ed6bbe.js"></script>
<script src="/My-Docs/1.ac610029.js"></script>
<script src="/My-Docs/2.ff8ccd9c.js"></script>
<script src="/My-Docs/42.523752d5.js"></script>
<script src="/My-Docs/43.aea2c726.js"></script>
<script src="/My-Docs/935f2afb.8c9dd23d.js"></script>
<script src="/My-Docs/17896441.29e4bed3.js"></script>
<script src="/My-Docs/991d0552.7e6e08b6.js"></script>
</body>
</html>