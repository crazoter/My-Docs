(window.webpackJsonp=window.webpackJsonp||[]).push([[28],{101:function(e,t,a){"use strict";a.d(t,"a",(function(){return m})),a.d(t,"b",(function(){return d}));var n=a(0),l=a.n(n);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function b(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,l=function(e,t){if(null==e)return{};var a,n,l={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(l[a]=e[a]);return l}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(l[a]=e[a])}return l}var c=l.a.createContext({}),p=function(e){var t=l.a.useContext(c),a=t;return e&&(a="function"==typeof e?e(t):b(b({},t),e)),a},m=function(e){var t=p(e.components);return l.a.createElement(c.Provider,{value:t},e.children)},s={inlineCode:"code",wrapper:function(e){var t=e.children;return l.a.createElement(l.a.Fragment,{},t)}},u=l.a.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,r=e.parentName,c=o(e,["components","mdxType","originalType","parentName"]),m=p(a),u=n,d=m["".concat(r,".").concat(u)]||m[u]||s[u]||i;return a?l.a.createElement(d,b(b({ref:t},c),{},{components:a})):l.a.createElement(d,b({ref:t},c))}));function d(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,r=new Array(i);r[0]=u;var b={};for(var o in t)hasOwnProperty.call(t,o)&&(b[o]=t[o]);b.originalType=e,b.mdxType="string"==typeof e?e:n,r[1]=b;for(var c=2;c<i;c++)r[c]=a[c];return l.a.createElement.apply(null,r)}return l.a.createElement.apply(null,a)}u.displayName="MDXCreateElement"},162:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/groupby-max-be4dcc64d1a8ebef95937a4e84b1f704.jpg"},163:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/groupby-max-sum-33ff5f981a0bb408858c107e9f564bd4.jpg"},86:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return r})),a.d(t,"metadata",(function(){return b})),a.d(t,"rightToc",(function(){return o})),a.d(t,"default",(function(){return p}));var n=a(2),l=a(6),i=(a(0),a(101)),r={title:"Python Cheatsheet"},b={unversionedId:"markdown/python",id:"markdown/python",isDocsHomePage:!1,title:"Python Cheatsheet",description:"Legend:",source:"@site/docs/markdown/python.md",slug:"/markdown/python",permalink:"/My-Docs/docs/markdown/python",editUrl:"https://github.com/crazoter/My-Docs/edit/master/website/docs/markdown/python.md",version:"current",sidebar:"someSidebar",previous:{title:"Machine Learning",permalink:"/My-Docs/docs/markdown/machine_learning"},next:{title:"Math",permalink:"/My-Docs/docs/markdown/math"}},o=[{value:"Pure Python",id:"pure-python",children:[]},{value:"Libraries / Modules",id:"libraries--modules",children:[{value:"Regex",id:"regex",children:[]},{value:"Recordlinkage (Join datasets w/o common UID)",id:"recordlinkage-join-datasets-wo-common-uid",children:[]},{value:"fuzzywuzzy (String Comparison)",id:"fuzzywuzzy-string-comparison",children:[]},{value:"missingno (Visualize missing data)",id:"missingno-visualize-missing-data",children:[]},{value:"scipy.stats (zscore)",id:"scipystats-zscore",children:[]},{value:"Textatistic (Evaluate word readability)",id:"textatistic-evaluate-word-readability",children:[]},{value:"spacy (tokenization and lemmatization)",id:"spacy-tokenization-and-lemmatization",children:[]},{value:"matplotlib.pyplot (Graphs &amp; Images)",id:"matplotlibpyplot-graphs--images",children:[]},{value:"Seaborn (Graphs)",id:"seaborn-graphs",children:[]},{value:"scikit-learn",id:"scikit-learn",children:[]}]},{value:"Numpy",id:"numpy",children:[]},{value:"Pandas",id:"pandas",children:[]}],c={rightToc:o};function p(e){var t=e.components,r=Object(l.a)(e,["components"]);return Object(i.b)("wrapper",Object(n.a)({},c,r,{components:t,mdxType:"MDXLayout"}),Object(i.b)("p",null,"Legend:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"#: Number, used for differentiating variables"),Object(i.b)("li",{parentName:"ul"},"L#: List."),Object(i.b)("li",{parentName:"ul"},"D#: Dictionary. "),Object(i.b)("li",{parentName:"ul"},"itr#: Iterable."),Object(i.b)("li",{parentName:"ul"},"DF#: Dataframe"),Object(i.b)("li",{parentName:"ul"},"mltIdx#: MultiIndex"),Object(i.b)("li",{parentName:"ul"},"idx: Index"),Object(i.b)("li",{parentName:"ul"},"int#: Integer variable")),Object(i.b)("h2",{id:"pure-python"},"Pure Python"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Exponentiation: val ** power"),Object(i.b)("li",{parentName:"ul"},"Type conversion: ",Object(i.b)("em",{parentName:"li"},"type"),"(val), where ",Object(i.b)("em",{parentName:"li"},"type")," in {int, float, str, bool}"),Object(i.b)("li",{parentName:"ul"},"Iterables",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Loop with Index"),": for idx, val in enumerate(itr)"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Generators (lazy loading iteration)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Creation: ",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"gen = iter(L / D / *range(i)*)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"gen = (x for x in list)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"gen = def fx(param): ... for x in param: yield x ...")))),Object(i.b)("li",{parentName:"ul"},"Use:    val = next(itr)"))))),Object(i.b)("li",{parentName:"ul"},"Lists",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Init with List Comprehension"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Format: ",Object(i.b)("inlineCode",{parentName:"li"},"[ (value) for (var_name) in (iterable) if (predicate) ]"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"e.g. [L","[0]"," for elem in list]"))))),Object(i.b)("li",{parentName:"ul"},"List of tuples:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Convert L to L of indexed tuples:"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"enumerate(itr, start=int1) = [(int1,itr[0]), (int1+1,itr[0])...]")))),Object(i.b)("li",{parentName:"ul"},"Merge two lists into a list of tuples:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"zip(*L1*,*L2*)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"returns zipObject: [ (L1","[0]",",L2","[0]","),  (L1","[1]",",L2","[1]",")... ]"),Object(i.b)("li",{parentName:"ul"},"Access zipObject contents: (*zipObj)"))),Object(i.b)("li",{parentName:"ul"},"Unzip: ",Object(i.b)("inlineCode",{parentName:"li"},"zip(*zipObj)")))))),Object(i.b)("li",{parentName:"ul"},"Count occurrences: ",Object(i.b)("inlineCode",{parentName:"li"},"list.count(obj)")))),Object(i.b)("li",{parentName:"ul"},"Dictionaries",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Init with Dictionary Comprehension"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Format: ",Object(i.b)("inlineCode",{parentName:"li"},"{ (key : value) for (var_name) in (iterable) if (predicate) }"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"e.g. {x : len(x) for x in list}"))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Init from list of tuples"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"dict(zip(L1,L2))")))))),Object(i.b)("li",{parentName:"ul"},"Functions:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Default params: x=default"),Object(i.b)("li",{parentName:"ul"},"Flexible list param: ",Object(i.b)("inlineCode",{parentName:"li"},"f(*args)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Usage: f(v1,v2,v3...)"))),Object(i.b)("li",{parentName:"ul"},"Flexible dict param: ",Object(i.b)("inlineCode",{parentName:"li"},"f(**kwargs)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Usage: f(k1=v1,k2=v2,k3=v3...)"))),Object(i.b)("li",{parentName:"ul"},"Multiple output: ",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"def fx(): return (x, y)"),Object(i.b)("li",{parentName:"ul"},"Multiple assignment:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"x,y = fx()"))))),Object(i.b)("li",{parentName:"ul"},"Global variables: ",Object(i.b)("inlineCode",{parentName:"li"},"global varname")),Object(i.b)("li",{parentName:"ul"},"Nested functions:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Variables & params of external f() is accessible"),Object(i.b)("li",{parentName:"ul"},"The function itself can be returned"),Object(i.b)("li",{parentName:"ul"},"Modify variables from nested f(): ",Object(i.b)("inlineCode",{parentName:"li"},"nonlocal varname")))))),Object(i.b)("li",{parentName:"ul"},"Functional Programming",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"map((lambda a: (transformation)), L)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"filter((lambda a: (predicate)), L)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"reduce((lambda a,b: ...), L) = result"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Import: ",Object(i.b)("inlineCode",{parentName:"li"},"from functools import reduce")))),Object(i.b)("li",{parentName:"ul"},"The lambda can be replaced with a concrete function"))),Object(i.b)("li",{parentName:"ul"},"Lambdas",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"(lambda (params): (body))")),Object(i.b)("li",{parentName:"ul"},"e.g. (lambda a: a+1) \u2261 def f(a): return a+1"),Object(i.b)("li",{parentName:"ul"},'No "return"'),Object(i.b)("li",{parentName:"ul"},"No multi-line"))),Object(i.b)("li",{parentName:"ul"},"Exception Handling",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"try: ... "),Object(i.b)("li",{parentName:"ul"},"except: ... "),Object(i.b)("li",{parentName:"ul"},"raise ",Object(i.b)("em",{parentName:"li"},"Error"),"(",Object(i.b)("em",{parentName:"li"},"msg"),")",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Error = {ValueError, TypeError, YourOwnErrClass}"))))),Object(i.b)("li",{parentName:"ul"},"I/O",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Open file:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"with open('filepath') as file_var"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"file_var.readline()"),": returns None if empty"))))),Object(i.b)("li",{parentName:"ul"},"Get script directory:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"dir_path = os.path.dirname(os.path.realpath(__file__))")))),Object(i.b)("li",{parentName:"ul"},"Get path to file relative to script directory:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"local_file = os.path.join(dir_path, 'path', 'to', 'local_file')")))))),Object(i.b)("li",{parentName:"ul"},"Datetime",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Req: ",Object(i.b)("inlineCode",{parentName:"li"},"import datetime as dt")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"dt.date.today()"))))),Object(i.b)("h2",{id:"libraries--modules"},"Libraries / Modules"),Object(i.b)("h3",{id:"regex"},"Regex"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Create Pattern"),": ",Object(i.b)("inlineCode",{parentName:"li"},'pattern = re.compile(r"regex_pattern")')),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Match"),": ",Object(i.b)("inlineCode",{parentName:"li"},"matches = re.match(pattern, str)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Returns None if no matches found"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get found values"),": ",Object(i.b)("inlineCode",{parentName:"li"},"matches.group(n), n = 0 if no groups defined")," "))),Object(i.b)("li",{parentName:"ul"})),Object(i.b)("h3",{id:"recordlinkage-join-datasets-wo-common-uid"},"Recordlinkage (Join datasets w/o common UID)"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"import recordlinkage")),Object(i.b)("li",{parentName:"ul"},"Purpose: ",Object(i.b)("strong",{parentName:"li"},"Join different datasets when they don't share a unique identifier.")," See ",Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://recordlinkage.readthedocs.io/en/latest/ref-index.html"}),"Documentation"),Object(i.b)("ol",{parentName:"li"},Object(i.b)("li",{parentName:"ol"},Object(i.b)("strong",{parentName:"li"},"Init an indexer"))),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"idxr = recordlinkage.Index()"))),Object(i.b)("ol",Object(n.a)({parentName:"li"},{start:2}),Object(i.b)("li",{parentName:"ol"},"Blocking: only ",Object(i.b)("strong",{parentName:"li"},"choose pairs of entries that have the same value under specified column"),' (e.g. "cuisine_type")')),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},'idxr.block("col_name")'))),Object(i.b)("ol",Object(n.a)({parentName:"li"},{start:3}),Object(i.b)("li",{parentName:"ol"},Object(i.b)("strong",{parentName:"li"},"Generate said pairs of indexes")," which agree on the equal columns")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"mltIdx_pairs = idxr.index(df1, df2)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Example pair: MultiIndex(","[(0,0),(0,1),(0,7),(1,0),(1,4)...]",")")))),Object(i.b)("ol",Object(n.a)({parentName:"li"},{start:4}),Object(i.b)("li",{parentName:"ol"},Object(i.b)("strong",{parentName:"li"},"Specify the columns to compare")," with a Compare object")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"comp = recordlinkage.Compare()"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Then, specify the columns to compare by:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"comp.exact('col_nm_in_df1', 'col_nm_in_df2', label='new_lbl_in_new_df')"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Entries must ",Object(i.b)("strong",{parentName:"li"},"exact match")," in the columns"),Object(i.b)("li",{parentName:"ul"},"e.g. comp.exact('city', 'city', label='city')"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"comp.string('col_nm_in_df1', 'col_nm_in_df2', label='new_lbl_in_new_df', threshold = dbl_frm_0-1)")," (threshold usually 0.8)"),Object(i.b)("li",{parentName:"ul"},"Entries must be ",Object(i.b)("strong",{parentName:"li"},"similar")," (in terms of string) in the columns")))))),Object(i.b)("ol",Object(n.a)({parentName:"li"},{start:5}),Object(i.b)("li",{parentName:"ol"},"Apply the Compare object to ",Object(i.b)("strong",{parentName:"li"},"get a dataframe highlighting potential matches"))),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"df_pttl_mtchs = comp.compute(mltIdx_pairs, df1, df2)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Structure of df_pttl_mtchs:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Index / Col 0: mltIdx_pairs"),Object(i.b)("li",{parentName:"ul"},"Columns: columns used for comparison",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"exact: 1 if equal else 0"),Object(i.b)("li",{parentName:"ul"},"string: 1 if threshold met, else 0")))))))),Object(i.b)("ol",Object(n.a)({parentName:"li"},{start:6}),Object(i.b)("li",{parentName:"ol"},Object(i.b)("strong",{parentName:"li"},"Filter matches")," from potential matches")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"df_mtchs = df_pttl_mtchs[df_pttl_mtchs.sum(axis=1) >= 3]"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"If the val == 1 then there's a match on that column. This counts the number of matched columns, and filters by that."),Object(i.b)("li",{parentName:"ul"},"In this case there were 3 columns so 3 was chosen")))),Object(i.b)("ol",Object(n.a)({parentName:"li"},{start:7}),Object(i.b)("li",{parentName:"ol"},Object(i.b)("strong",{parentName:"li"},"Select matched indexes")," for one of the DFs (in this case df2)",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"idx_df2_mtched = df_mtchs.index.get_level_values(1)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"df_pttl_mtchs & df_mtchs use a MultiIndex. "),Object(i.b)("li",{parentName:"ul"},"df_mtchs.index.get_level_values(0) = df1's indexes, (1) = df2's indexes"))))),Object(i.b)("li",{parentName:"ol"},Object(i.b)("strong",{parentName:"li"},"From df2, remove entries that match df1's entries"))),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"df2_notInDf1 = df2[~df2.index.isin(idx_df2_mtched)]"))),Object(i.b)("ol",Object(n.a)({parentName:"li"},{start:9}),Object(i.b)("li",{parentName:"ol"},Object(i.b)("strong",{parentName:"li"},"Join df1 and the new df2 entries"))),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"df1.append(df2_notInDf1)"))))),Object(i.b)("h3",{id:"fuzzywuzzy-string-comparison"},"fuzzywuzzy (String Comparison)"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Import"),": ",Object(i.b)("inlineCode",{parentName:"li"},"from fuzzywuzzy import process")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Test similarity:")," ",Object(i.b)("inlineCode",{parentName:"li"},"process.extract('target_word', arr_of_candidate_words, length_of_arr)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Returns array of tuples: ",Object(i.b)("inlineCode",{parentName:"li"},"[('candidate_word', similarity_score), ...]"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"similarity_score: from 0 - 100, 100 as perfect, 80 as close enough")))))),Object(i.b)("h3",{id:"missingno-visualize-missing-data"},"missingno (Visualize missing data)"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"import missingno as msno")),Object(i.b)("li",{parentName:"ul"},"msno.matrix(df_with_missingvals); plt.show()")),Object(i.b)("h3",{id:"scipystats-zscore"},"scipy.stats (zscore)"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"from scipy.stats import zscore")),Object(i.b)("li",{parentName:"ul"},"calculate zscore values: ",Object(i.b)("inlineCode",{parentName:"li"},"zscore(df['col'])"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"z-score is the number of standard deviations by which an observation is above the mean - so if it is negative, it means the observation is below the mean.")))),Object(i.b)("h3",{id:"textatistic-evaluate-word-readability"},"Textatistic (Evaluate word readability)"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"from textatistic import Textatistic")),Object(i.b)("li",{parentName:"ul"},"Compute scores: ",Object(i.b)("inlineCode",{parentName:"li"},"scores = Textatistic(article/string).scores")),Object(i.b)("li",{parentName:"ul"},"Get Flesch score: ",Object(i.b)("inlineCode",{parentName:"li"},"scores['flesch_score']")),Object(i.b)("li",{parentName:"ul"},"Get gunningfog: ",Object(i.b)("inlineCode",{parentName:"li"},"scores['gunningfog_score']"))),Object(i.b)("h3",{id:"spacy-tokenization-and-lemmatization"},"spacy (tokenization and lemmatization)"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"import spacy")),Object(i.b)("li",{parentName:"ul"},"Tokenization")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"import spacy\n\n# Load the en_core_web_sm model which comes with the spaCy library (see https://spacy.io/models/en)\nnlp = spacy.load('en_core_web_sm')\n\n# Create a Doc object\ndoc = nlp(gettysburg)\n\n# Generate the tokens\ntokens = [token.text for token in doc]\n")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Lemmatization (accuracy dependent on moduel)")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"import spacy\n\n# Load the en_core_web_sm model\nnlp = spacy.load('en_core_web_sm')\n\n# Create a Doc object\ndoc = nlp(gettysburg)\n\n# Generate lemmas (accuracy dependent on model)\nlemmas = [token.lemma_ for token in doc]\n\n# Convert lemmas into a string\nprint(' '.join(lemmas))\n")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Preprocess with lemmatization, removing non alphabeticals")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"# Function to preprocess text\ndef preprocess(text):\n    # Create Doc object\n    doc = nlp(text, disable=['ner', 'parser'])\n    # Generate lemmas\n    lemmas = [token.lemma_ for token in doc]\n    # Remove stopwords and non-alphabetic characters\n    a_lemmas = [lemma for lemma in lemmas \n            if lemma.isalpha() and lemma not in stopwords]\n    \n    return ' '.join(a_lemmas)\n  \n# Apply preprocess to ted['transcript']\nted['transcript'] = ted['transcript'].apply(preprocess)\nprint(ted['transcript'])\n")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"POS (piece-of-speech) tagging ")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"# Load the en_core_web_sm model\nnlp = spacy.load('en_core_web_sm')\n\n# Create a Doc object\ndoc = nlp(lotf)\n\n# Generate tokens and pos tags\npos = [(token.text, token.pos_) for token in doc]\nprint(pos) \n# Output: [('He', 'PRON'), ('found', 'VERB'), ('himself', 'PRON'), ('understanding', 'VERB') ...\n")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Named Entities Recognition (NER)")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"# Load the required model\nnlp = spacy.load('en_core_web_sm')\n\n# Create a Doc instance \ntext = 'Sundar Pichai is the CEO of Google. Its headquarters is in Mountain View.'\ndoc = nlp(text)\n\n# Print all named entities and their labels\nfor ent in doc.ents:\n    print(ent.text, ent.label_)\n\"\"\"\nOutput:\n    Sundar Pichai ORG\n    Google ORG\n    Mountain View GPE\n\"\"\"\n\n# Alternatively:\ndef find_persons(text):\n  # Create Doc object\n  doc = nlp(text)\n  \n  # Identify the persons\n  persons = [ent.text for ent in doc.ents if ent.label_ == 'PERSON']\n  \n  # Return persons\n  return persons\n\nprint(find_persons(tc))\n")),Object(i.b)("h3",{id:"matplotlibpyplot-graphs--images"},"matplotlib.pyplot (Graphs & Images)"),Object(i.b)("p",null,Object(i.b)("inlineCode",{parentName:"p"},"import matplotlib.pyplot as plt")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Think of ",Object(i.b)("inlineCode",{parentName:"p"},"plt")," as some kind of a global variable to attach stuff to")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Change Styles:"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Use style"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.style.use(style_name)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Show available styles"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.style.available")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Improve the spacing between subplots"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.tight_layout()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Hide gridlines"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.grid('off')")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Hide axes"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.axis('off')")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Graphs"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Create multiple graphs:"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Automatically using ",Object(i.b)("inlineCode",{parentName:"li"},"plt.subplot(rows, columns, active_subplot_idx)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Call the function with a new ",Object(i.b)("inlineCode",{parentName:"li"},"active_subplot_idx")," = row x rowlen * column to change the current graph.",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"active_subplot_idx")," starts from 1"))))),Object(i.b)("li",{parentName:"ul"},"Specify axes directly: "),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Define bounding box (axes)"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.axes([xlower, ylower, width_%, height_%])"),", args passed as a list",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Think of these as rectangle bounds of your current graph.",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"e.g. if you want 2 graphs side-by-side: ",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"First set the axes for the left one ",Object(i.b)("inlineCode",{parentName:"li"},"plt.axes([0.05, 0.05, 0.425, 0.9])")," "),Object(i.b)("li",{parentName:"ul"},"Then plot the left graph ",Object(i.b)("inlineCode",{parentName:"li"},"plt.plot(year, physical_sciences, color='blue')")),Object(i.b)("li",{parentName:"ul"},"The set the axes for the right one ",Object(i.b)("inlineCode",{parentName:"li"},"plt.axes([0.525, 0.05, 0.425, 0.9])")),Object(i.b)("li",{parentName:"ul"},"and plot that graph ",Object(i.b)("inlineCode",{parentName:"li"},"plt.plot(year, computer_science, color='red')")))))))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Plot graph in active subplot:"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Plot line"),":")),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"plt.plot(\n    OPTION 1 WITH TWO LISTS: x_positions_of_points, y_positions_of_points, \n    OPTION 2 WITH 1 DATAFRAME: dataframe_of_x_and_y \n    color='blue', \n    label=str     # Used to label the line in the legend\n)\n")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Scatter"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.scatter(x_data, y_data, label='data', color='red', marker='o')")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Histogram"),": ")),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"plt.hist(pixels, bins=64, \n    range=(0, 256),   # x-axis range\n    normed=True,      # normalized histogram\n    cumulative=True,  # cumulative density function instead of probability density function\n    color='red', \n    alpha=0.4,\n)\n\n# Alternatively\ndataframe.hist()\n")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Boxplot"),": ",Object(i.b)("inlineCode",{parentName:"li"},"dataframe.boxplot(column = [y_axis_col_values], by=[x_axis_col_values])")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Add title"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.title(str)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Change x and y labels"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.xlabel(str)")," and ",Object(i.b)("inlineCode",{parentName:"li"},"plt.ylabel(str)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Change x and y limits (set range)"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.xlim(lower,upper)")," and ",Object(i.b)("inlineCode",{parentName:"li"},"plt.ylim(lower,upper)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Inclusive"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Change both at the same time"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.axis((x_lower,x_upper,y_lower, y_upper))")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Configuring xticks / yticks"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.xticks(rotation=degs)")," and ",Object(i.b)("inlineCode",{parentName:"li"},"plt.yticks(rotation=degs)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"ticks: the markers showing the coordinates on the x and y axis"),Object(i.b)("li",{parentName:"ul"},"rotation: angle at which ticks are displayed"))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Add legend"),": ",Object(i.b)("inlineCode",{parentName:"p"},"plt.legend(loc='lower center')"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Overlay plots"),": ",Object(i.b)("inlineCode",{parentName:"p"},"plt.twinx()")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Use plt.twinx() to overlay plots with different vertical scales on a common horizontal axis."))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Annotate")),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"plt.annotate(text, \n    xy=(x_pos, y_pos),    # xy of value you're pointing to\n    xytext=(x_pos, y_pos), \n    arrowprops=dict(facecolor='black')\n)\n"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"2D histogram"),":"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"plt.hist2d(horizontal_data, vertical_data, bins=(x_cols, y_rows), range=((x_min, x_max), (y_min, y_max)))")),Object(i.b)("li",{parentName:"ul"},"Range is optional"),Object(i.b)("li",{parentName:"ul"},"Instead of plotting the points directly on a graph, you turn it into something of a density map; the graph is split into a grid, and boxes with a lot of points will have a color of higher intensity."))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"2D hex histogram"),":"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"plt.hexbin(horizontal_data, vertical_data, gridsize=(x_cols, y_rows), extent=(x_min, x_max, y_min, y_max))")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Display points w/ color"),": ",Object(i.b)("inlineCode",{parentName:"p"},"plt.pcolor(2D_arr,...)")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Add param ",Object(i.b)("inlineCode",{parentName:"li"},"cmap='Blues'")," to config colormapping to Blues"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Display color and intensity mapping"),": ",Object(i.b)("inlineCode",{parentName:"p"},"plt.colorbar()")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Note that the bottom left part of the image maps to the top left part of the numpy array"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Display points as contours"),": ",Object(i.b)("inlineCode",{parentName:"p"},"plt.contour(X, Y, Z, contour_count, cmap='color_map')")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Filled: ",Object(i.b)("inlineCode",{parentName:"li"},"plt.contourf(...)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://jakevdp.github.io/PythonDataScienceHandbook/04.04-density-and-contour-plots.html"}),"See")))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Images"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Load image"),": ",Object(i.b)("inlineCode",{parentName:"li"},"npRGB = plt.imread(filepath)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Display image"),": ")),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"plt.imshow(npRGB,\n    cmap='gray',\n    extent=(-1, 1, -1, 1) # horizontal extent from -1 to 1, vertical extent from -1 to 1\n    aspect=1              # aspect ratio (# of vertical pixels : # of horizontal pixels). \n                          # \\lt 1 means img is squashed downwards; \\gt 1 means img is stretched upwards\n)\n")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Add cmap if only 1 channel"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"RGB to monochannel"),": ",Object(i.b)("inlineCode",{parentName:"li"},"npRGB.sum(axis=2)")),Object(i.b)("li",{parentName:"ul"},"Others:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Split RGB into channels:"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"red, green, blue = img[:,:,0], img[:,:,1], img[:,:,2]")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Flatten monochannel image (without modifying values) into 1-D array"),": ",Object(i.b)("inlineCode",{parentName:"li"},"image.flatten()")))),Object(i.b)("li",{parentName:"ul"},"Normalize intensity:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"256*(img-img.min())/(img.max()-img.min())")))))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Export:"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Show on GUI"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.show()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Save to file"),": ",Object(i.b)("inlineCode",{parentName:"li"},"plt.savefig(filepath)"))))),Object(i.b)("h3",{id:"seaborn-graphs"},"Seaborn (Graphs)"),Object(i.b)("p",null,Object(i.b)("inlineCode",{parentName:"p"},"import seaborn as sns")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Simple linear regression"),":"),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"sns.lmplot(x='x_pos_col_in_df', y='y_pos_col_in_df', data=dataframe\n    hue='categorical_col_in_df', # This col is categorical; will be used to group the points by colour\n    row='groupby_row_wise'\n    palette='Set1'\n)\n")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"straight line best fit"),Object(i.b)("li",{parentName:"ul"},"hue: e.g. you have a col \"gender\" that allows only {'M','F'}. ",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Graph will color points that have value 'M' to one color, and 'F' to another color (i.e. groupby)"))),Object(i.b)("li",{parentName:"ul"},"row: same purpose as hue, but groupby row-wise",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"i.e. Segregate points by each category and plot a separate graph for each"))),Object(i.b)("li",{parentName:"ul"},"plots on current plt graph. Use ",Object(i.b)("inlineCode",{parentName:"li"},"plt.show()")," to show "))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"2nd order regression"),": "),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"sns.regplot(x='x_col_in_df', y='y_col_in_df', data=dataframe,\n    color='green', \n    scatter=None,         # Set scatter to None if you don't want to plot the scatter points; else ignore this line\n    order=2,              # 1 for simple lin. regr., 2 for 2nd order etc\n    label='legend_label'  # label for legend\n)\n")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"curved line best fit"),Object(i.b)("li",{parentName:"ul"}))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Residual plot"),": ",Object(i.b)("inlineCode",{parentName:"p"},"sns.residplot(x='x_col_in_df', y='y_col_in_df', data=dataframe, color=color_str)")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Visualize how far datapoints diverge from the regression line."))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Strip plot"),": A scatter plot where the x axis represents a categorical variable."),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"sns.stripplot(x='x_col_in_df', y='y_col_in_df', data=df,\n    size = n,   # Size of dots\n    jitter=True # Useful when many points overlap, easier to see distribution. \n)\n")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://seaborn.pydata.org/generated/seaborn.stripplot.html"}),"Documentation")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Swarm plot"),": Similar to strip plot, but the points visually spread out to avoid overlap"),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"sns.swarmplot(x='x_col_in_df', y='y_col_in_df', data=df,\n    orient = 'h'/'v'  # h: y is now the categorical var. v: same as stripplot\n    size = n,         # Size of dots\n    hue='col',        # Categorical column to colour points by\n)\n"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Violin plot"),": Similar to a box plot, with the addition of a rotated kernel density plot on each side"),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"sns.violinplot(x='x_col_in_df', y='y_col_in_df', data=df,\n    color='lightgray',  # If you want all violins to be of the same color\n    inner=None          # Points are visualized in the center of each x coord. inner=None to only show the violin body.\n)\n"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Joint plot"),": Main plot in the middle defined by ",Object(i.b)("inlineCode",{parentName:"p"},"kind"),", combined with histograms aligned to the x and y axis at the side."),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"sns.jointplot(x='hp', y='mpg',data=auto,\n    kind = 'scatter' | 'reg' | 'resid' | 'kde' | 'hex'\n)\n")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"kind='scatter': scatter plot of the data points"),Object(i.b)("li",{parentName:"ul"},"kind='reg': regression plot (default order 1)"),Object(i.b)("li",{parentName:"ul"},"kind='resid': residual plot"),Object(i.b)("li",{parentName:"ul"},"kind='kde': kernel density estimate of the joint distribution"),Object(i.b)("li",{parentName:"ul"},"kind='hex': hexbin plot of the joint distribution"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Pair(wise) plot"),": Take every pairwise combination of every non-categorical column in dataframe and plot main plot + histogram."),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"sns.pairplot(df, kind = 'scatter' | 'reg' | 'resid' | 'kde' | 'hex'\n    hue = 'categorical_col' # Categorical column to colour points by\n)```\n\n"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Heatmap"),": Good for visualizing 2D arrays (e.g. covariance matrices)"),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"sns.heatmap(df)\n")))),Object(i.b)("h3",{id:"scikit-learn"},"scikit-learn"),Object(i.b)("p",null,Object(i.b)("inlineCode",{parentName:"p"},"import sklearn"),"\n",Object(i.b)("strong",{parentName:"p"},"train_test_split")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"from sklearn.model_selection import train_test_split")),Object(i.b)("li",{parentName:"ul"},"Use stratified sampling to split up the dataset according to the categorical_y_data dataset",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"X_train, X_test, y_train, y_test = train_test_split(data_x, categorical_y_data, stratify=categorical_y_data)")),Object(i.b)("li",{parentName:"ul"},"Stratified: Make the distribution of each feature as close as possible to the original in the training and test sets"),Object(i.b)("li",{parentName:"ul"},"75% into training set and 25% into test set")))),Object(i.b)("p",null,Object(i.b)("strong",{parentName:"p"},"Concepts")),Object(i.b)("p",null,"Data Standardization (normalization):"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Preprocessing task performed on numerical, continuous data to ",Object(i.b)("strong",{parentName:"li"},"make it normally distributed"),". Standardize (assuming linear space) when:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("ol",{parentName:"li"},Object(i.b)("li",{parentName:"ol"},"Using a model that is in a linear space (any kind of model that uses a linear distance metric or operates in a linear space like k-nearest neighbors, linear regression, or k-means clustering). The model is assuming that the data and features you're giving it are related in a linear fashion, or can be measured with a linear distance metric. "))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("ol",Object(n.a)({parentName:"li"},{start:2}),Object(i.b)("li",{parentName:"ol"},"When a feature or features in your dataset have high variance ; if a feature in your dataset has a variance that's an order of magnitude or more greater than the other features, this could impact the model's ability to learn from other features in the dataset. "))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("ol",Object(n.a)({parentName:"li"},{start:3}),Object(i.b)("li",{parentName:"ol"},"When features are of different scales e.g. height & weight. To compare these features, they must be in the same linear space, and therefore must be standardized in some way. "))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"StandardScaler"),": For Data Standardization",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Finds mean and centers data around it (no limit to max / min)"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Import"),": ",Object(i.b)("inlineCode",{parentName:"li"},"from sklearn.preprocessing import StandardScaler")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Creation"),": ",Object(i.b)("inlineCode",{parentName:"li"},"ss = StandardScaler()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Fit"),": ",Object(i.b)("inlineCode",{parentName:"li"},"ss.fit(training_df_column)")," (Call before transform)",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"only fit with training data to avoid data leakage (won't have access to test data)"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Normalize scale"),": ",Object(i.b)("inlineCode",{parentName:"li"},"ss.transform(dataframe_subset (columns))"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"transform training data"),Object(i.b)("li",{parentName:"ul"},"Use ",Object(i.b)("inlineCode",{parentName:"li"},".fit_transform(...)")," to fit, then transform data"))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"MinMaxScaling"),": For normalizing linear values to 0-1 by squashing min and max range to 0-1",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Use only when you know your data has a strict lower and upper bound"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Import"),": ",Object(i.b)("inlineCode",{parentName:"li"},"from sklearn.preprocessing import MinMaxScaler")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Creation"),": ",Object(i.b)("inlineCode",{parentName:"li"},"MM_scaler = MinMaxScaler()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Fit"),": ",Object(i.b)("inlineCode",{parentName:"li"},"MM_scaler.fit(training_df_column)")," (Call before transform)",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"only fit with training data"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Transform"),": ",Object(i.b)("inlineCode",{parentName:"li"},"resultantCol = MM_scaler.transform(training_df_column)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"transform training data"),Object(i.b)("li",{parentName:"ul"},"Use ",Object(i.b)("inlineCode",{parentName:"li"},".fit_transform(...)")," to fit, then transform data"))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Log transform"),": ",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Import"),": ",Object(i.b)("inlineCode",{parentName:"li"},"from sklearn.preprocessing import PowerTransformer")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Creation"),": ",Object(i.b)("inlineCode",{parentName:"li"},"pow_trans = PowerTransformer()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Fit"),": ",Object(i.b)("inlineCode",{parentName:"li"},"pow_trans.fit(training_df_column)")," (Call before transform)",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"only fit with training data"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Normalize scale"),": ",Object(i.b)("inlineCode",{parentName:"li"},"pow_trans.transform(dataframe_subset (columns))"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"transform training data"),Object(i.b)("li",{parentName:"ul"},"Use ",Object(i.b)("inlineCode",{parentName:"li"},".fit_transform(...)")," to fit, then transform data")))))),Object(i.b)("p",null,"Data Sanitization"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Outlier Removal",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Quantile (percentage) based",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("ol",{parentName:"li"},Object(i.b)("li",{parentName:"ol"},"Find quantile: ",Object(i.b)("inlineCode",{parentName:"li"},"quantile = dataframe['col'].quantile(0.95)")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("ol",Object(n.a)({parentName:"li"},{start:2}),Object(i.b)("li",{parentName:"ol"},"Trim: ",Object(i.b)("inlineCode",{parentName:"li"},"trimmed_df = dataframe[dataframe['col'] < quantile]")))))),Object(i.b)("li",{parentName:"ul"},"standard dev based",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Get mean and std dev"),Object(i.b)("li",{parentName:"ul"},"Calculate cutoff e.g. ",Object(i.b)("inlineCode",{parentName:"li"},"3 * std"),", and lower (",Object(i.b)("inlineCode",{parentName:"li"},"mean - cutoff"),") + upper (",Object(i.b)("inlineCode",{parentName:"li"},"mean + cutoff"),") bounds"),Object(i.b)("li",{parentName:"ul"},"Trim outliers ",Object(i.b)("inlineCode",{parentName:"li"},"df[(df['col'] < upper) & (df['col'] > lower)]")))))),Object(i.b)("li",{parentName:"ul"},"Text preprocessing tricks",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Trim whitespace"),Object(i.b)("li",{parentName:"ul"},"Remove punctuation"),Object(i.b)("li",{parentName:"ul"},"Remove commonly occurring words or stopwords"),Object(i.b)("li",{parentName:"ul"},"Expanding contracted words (e.g. can't)"),Object(i.b)("li",{parentName:"ul"},"Remove special characters such as numbers and emojis."),Object(i.b)("li",{parentName:"ul"},"Done using ",Object(i.b)("strong",{parentName:"li"},"tokenization")," (split corpus by space)"),Object(i.b)("li",{parentName:"ul"},"Done by ",Object(i.b)("strong",{parentName:"li"},"lemmatization"),' (convert word into base form e.g. "eating" "ate" into "eat")')))),Object(i.b)("p",null,"Feature Engineering"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Descript: Creation of new features from existing features (e.g. string/timestamp subsetting, aggregate numeric data across columns etc)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"LabelEncoder"),": Converting labelled column into {0,1} column"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Creation"),": ",Object(i.b)("inlineCode",{parentName:"li"},"enc = LabelEncoder()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Encode as binary"),": ",Object(i.b)("inlineCode",{parentName:"li"},"new_col = enc.fit_transform(dataframe['col'])")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"One Hot Encoding"),": Convert column of categories into 2D binary array"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Do this instead of mapping categories to numbers, to avoid encoding ordering to the categories"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Dummy Encoding"),": Same as one-hot encoding, but the first column dropped. Membership to the first column is indicated (implied) when all OHE are set to 0."),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Both OHE & Dummy use the same command:"))),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"pd.get_dummies(dataframe,\n    columns = [column_labels], \n    drop_first=True, \n    prefix='col_prefix'\n)\n"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"CountVectorizer"),": Vectorize text with word count"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Bag of words (BoW): Given a vocabulary e.g. ","['a','sock','dog']",", convert corpus into a dictionary counting number of times the words occur e.g. ","[0, 2, 1]"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Import"),": ",Object(i.b)("inlineCode",{parentName:"li"},"from sklearn.feature_extraction.text import CountVectorizer")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Creation"),": ")),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),'cv = CountVectorizer(\n    lowercase = bool,\n    stop_words = \'english\' # optional for excluding stop words in the BoW vector\n    min_df: 0-1,   # Use only words that occur in more than this percentage of documents. This can be used to remove outlier words that will not generalize across texts.\n    max_df: 0-1,   # Use only words that occur in less than this percentage of documents. This is useful to eliminate very common words that occur in every corpus without adding value such as "and" or "the".\n)\n')),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Fit"),": ",Object(i.b)("inlineCode",{parentName:"li"},"cv.fit(speech_df['text_clean'])")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get word list"),": ",Object(i.b)("inlineCode",{parentName:"li"},"cv.get_feature_names()")," "),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Transform"),": ",Object(i.b)("inlineCode",{parentName:"li"},"cv_transformed = cv.transform(speech_df['text_clean'])"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"returns sparse array"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"To array"),": ",Object(i.b)("inlineCode",{parentName:"li"},"cv_transformed.toarray()"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"1 row per block of text and a column for each of the features generated by the vectorizer"))))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"tf-idf"),": Term Frequency - Inverse Document Frequency vector"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Descript: Text vectorization converts text to numerical input"),Object(i.b)("li",{parentName:"ul"},"[(# of word occurences) / (total words in document)]"," / log(# of docs word is in / total number of docs)",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Divide proportion of word occurence by proportion that it appears in all documents",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"reduces value of common words"))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Import"),": ",Object(i.b)("inlineCode",{parentName:"li"},"from sklearn.feature_extraction.text import TfidfVectorizer")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Creation"),": ")),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),'tfidf_vec = TfidfVectorizer(\n  max_features=n, \n  stop_words=\'english\',\n  ngram_range = (start, stop) # Adding some ordering. bi-gram ("not happy") tri-gram ("never not happy"). Tries to fix bag of words problem\n)\n')),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"stop_words will remove common words like 'the'")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Transform"),": ",Object(i.b)("inlineCode",{parentName:"p"},"text_tfidf = tfidf_vec.fit_transform(title_text)")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"returns sparse array"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"To array"),": ",Object(i.b)("inlineCode",{parentName:"li"},"cv_transformed.toarray()")),Object(i.b)("li",{parentName:"ul"},"Indices and weights will be stored in the tfidf vector ",Object(i.b)("inlineCode",{parentName:"li"},"text_tfidf")),Object(i.b)("li",{parentName:"ul"},"Vocabulary and weights will be stored in the TfidfVectorizer ",Object(i.b)("inlineCode",{parentName:"li"},"tfidf_vec"),"."),Object(i.b)("li",{parentName:"ul"},"Example")),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"# Instantiate TfidfVectorizer\ntv = TfidfVectorizer(max_features=100, stop_words='english')\n\n# Fit the vectroizer and transform the data\ntv_transformed = tv.fit_transform(train_speech_df['text_clean'])\n\n# Transform test data\ntest_tv_transformed = tv.transform(test_speech_df['text_clean'])\n\n# Create new features for the test set\ntest_tv_df = pd.DataFrame(test_tv_transformed.toarray(), \n                          columns=tv.get_feature_names()).add_prefix('TFIDF_')\nprint(test_tv_df.head())\n")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get word list"),": ",Object(i.b)("inlineCode",{parentName:"li"},"cv.get_feature_names()")," "),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get word to index map"),": ",Object(i.b)("inlineCode",{parentName:"li"},"str_idx_map = tfidf_vec.vocabulary_"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get index to word map"),": ",Object(i.b)("inlineCode",{parentName:"li"},"idx_str_map = {v:k for k,v in tfidf_vec.vocabulary_.items()}")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get weights for every word in row"),": ",Object(i.b)("inlineCode",{parentName:"li"},"text_tfidf[row_index].data"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"If row_index is not number, use ",Object(i.b)("inlineCode",{parentName:"li"},"iloc[n]")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get indices for every word in row"),": ",Object(i.b)("inlineCode",{parentName:"li"},"text_tfidf[row_index].indices"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get indices to weights map for row"),": ",Object(i.b)("inlineCode",{parentName:"li"},"idx_wgts_map = dict( zip(text_tfidf[row_index].indices, text_tfidf[row_index].data)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get word to weights map for row"),": ",Object(i.b)("inlineCode",{parentName:"li"},"str_wgts_map = {idx_str_map[i]:idx_wgts_map[i] for i in text_tfidf[row_index].indices}")))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get indices of top n weights"),": ",Object(i.b)("inlineCode",{parentName:"li"},"top_n_idx = pd.Series(str_wgts_map).sort_values(ascending=False)[:top_n].index")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get words of top n weights"),": ",Object(i.b)("inlineCode",{parentName:"li"},"top_n_str = [idx_str_map[i] for i in top_n_idx]"))))))),Object(i.b)("p",null,"Feature Selection"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Removing ",Object(i.b)("strong",{parentName:"li"},"redundant")," (noisy|correlated|duplicated) features.",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"e.g. features that generated an aggregate statistic")))),Object(i.b)("p",null,"Feature Extraction"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Transform data into new features"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Dimensionality Reduction"),": Reduce feature space",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Turning numericals into binned vals / binary"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Principle Component Analysis (PCA)"),": linear transformation to uncorrelated space",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Variance captured in a meaningful way by combining features into components"),Object(i.b)("li",{parentName:"ul"},"Number of components = number of input features"),Object(i.b)("li",{parentName:"ul"},"Difficult to interpret components, should be left to the end-of-preprocessing journey"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Creation"),": ",Object(i.b)("inlineCode",{parentName:"li"},"pca = PCA()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Transform"),": ",Object(i.b)("inlineCode",{parentName:"li"},"transformed_X = pca.fit_transform(dataframe_X)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"How much variance is explained by each component"),": ",Object(i.b)("inlineCode",{parentName:"li"},"pca.explained_variance_ratio_")))))))),Object(i.b)("li",{parentName:"ul"},"POS tagging (Parts of Speech) (e.g. Pronoun, verb, article, noun)"),Object(i.b)("li",{parentName:"ul"},"Named Entity Recognition (NER) (e.g. Person, Organization)")),Object(i.b)("p",null,"Models"),Object(i.b)("p",null,Object(i.b)("strong",{parentName:"p"},"K-Nearest Neighbour (KNN)")," Classifier. ",Object(i.b)("a",Object(n.a)({parentName:"p"},{href:"https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn"}),"See")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Return label of closest neighbour as prediction"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Import"),": ",Object(i.b)("inlineCode",{parentName:"li"},"from sklearn.neighbors import KNeighborsClassifier")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Create"),": ",Object(i.b)("inlineCode",{parentName:"li"},"knn = KNeighborsClassifier(n_neighbors=3)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Training"),": ",Object(i.b)("inlineCode",{parentName:"li"},"knn.fit(X_train (features), y_train (labels))")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Scoring"),": ",Object(i.b)("inlineCode",{parentName:"li"},"knn.score(X_test, y_test)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Predict"),": ",Object(i.b)("inlineCode",{parentName:"li"},"predicted = knn.predict(input)"))),Object(i.b)("p",null,Object(i.b)("strong",{parentName:"p"},"Naive Bayes")," Classifier: "),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Assumes features are independent, works well with high-dimensional text data"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Training"),": ",Object(i.b)("inlineCode",{parentName:"li"},"nb.fit(X_train (features), y_train (labels))")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Scoring"),": ",Object(i.b)("inlineCode",{parentName:"li"},"nb.score(X_test, y_test)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Predict"),": ",Object(i.b)("inlineCode",{parentName:"li"},"predicted = nb.predict(input)"))),Object(i.b)("h2",{id:"numpy"},"Numpy"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Import"),": ",Object(i.b)("inlineCode",{parentName:"li"},"import numpy as np")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Numpy Array"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Creation",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Create array"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.array(list)")))),Object(i.b)("li",{parentName:"ul"},"Attributes",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Shape"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np_list.shape")))),Object(i.b)("li",{parentName:"ul"},"Unary Operations",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Transpose array"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.transpose(list)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Reshape"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.reshape(np_array, (new, shape, dimensions))"),". ",Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://numpy.org/doc/stable/reference/generated/numpy.reshape.html"}),"Doc")))),Object(i.b)("li",{parentName:"ul"},"Operation with scalar",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Slicing 2D numpy array (get row / get col)"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np_2d[row,:]"),", ",Object(i.b)("inlineCode",{parentName:"li"},"np_2d[:,col]")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Mass multiplication"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np_list *= val")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Iterate 2D array as 1D"),": ",Object(i.b)("inlineCode",{parentName:"li"},"for x in np.nditer(np_2d_arr)")))),Object(i.b)("li",{parentName:"ul"},"Operations involving two numpy arrays",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Mass operation"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np_list3 = np_list1 / np_list2")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Union"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.logical_and(arr1, arr2)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Intersect"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.logical_or(a1,a2)"),Object(i.b)("strong",{parentName:"li"},"* Negation of numpy arr"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.logical_not(a1,a2)")))),Object(i.b)("li",{parentName:"ul"},"Operations involving boolean arrays",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Generate boolean array by applying condition to array"),": ",Object(i.b)("inlineCode",{parentName:"li"},"bool_val = np_list > val")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Subsetting with bool array"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np_list[bool_val]")))),Object(i.b)("li",{parentName:"ul"},"Aggregation Operations",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Mean"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.mean(np_list)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Median"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.median(np_list)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Std Dev"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.std(np_list)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Variance"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.var(np_list)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Correlation Coeff"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.corrcef(np_list1, np_list2)")))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Numpy Random"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Init with Seed"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.random.seed(seed)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Generate Float")," 0-1: ",Object(i.b)("inlineCode",{parentName:"li"}," np.random.rand()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Generate Integer"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.random.randint(lowerIncl, upperExcl)")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Definitions"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"NaN"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.nan")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Operations"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Log10"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.log10(nd_arr or dataframe)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"1D interpolation"),": ",Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://numpy.org/doc/stable/reference/generated/numpy.interp.html"}),"doc"))),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"np.interp(xcoords_to_interpolate, data_xcoords, data_ycoords, left=None, right=None, period=None)\n"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Generate uniformly spaced list"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.linspace(lower_lim, upper_lim, number_of_items)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Meshgrid: create a grid by using coordinates of each dimension"),": ",Object(i.b)("inlineCode",{parentName:"li"},"np.meshgrid(columns, rows)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://stackoverflow.com/a/42404323"}),"See"))))),Object(i.b)("h2",{id:"pandas"},"Pandas"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Import"),": ",Object(i.b)("inlineCode",{parentName:"li"},"import pandas as pd"))),Object(i.b)("h4",{id:"series-pandas-labelled-list"},"Series (Pandas labelled list)"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"From list"),": ",Object(i.b)("inlineCode",{parentName:"li"},"pd.Series(array, ..., index=arr)"))),Object(i.b)("h4",{id:"dataframe-pandas-labelled-excel-sheets--dictionaries"},"DataFrame (Pandas labelled excel sheets / dictionaries)"),Object(i.b)("p",null,"Creation / Conversion"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"From Dictionary"),": ",Object(i.b)("inlineCode",{parentName:"p"},"pd.DataFrame(dict)"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"From CSV File"),": "),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"dataframe = pd.read_csv(string_filename, \n    delimiter   = str,          # The shorthand 'sep' serves the same purpose\n    header      = line_no_start_of_data, \n    index_col   = i, # Column to use as row labels of the df. Set to False to force pandas not to use the first column as the index, or to a col name if you want to use that col\n\n    [chunksize   = n, \n    names       = new_col_labels_list, \n    comment     = str_prefix, \n    parse_dates = [date_col...]\n)\n")),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},'Note that dataframes are iterables, so you can use "next(iterable)" on them (to get them in the chunksize)'))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Converting to set"),": ",Object(i.b)("inlineCode",{parentName:"p"},"set(df['col'])"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"add_prefix to all cols"),": ",Object(i.b)("inlineCode",{parentName:"p"},"df.add_prefix(str)")))),Object(i.b)("p",null,"Accessing / Selection"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"For Loop for each row")," (note that row is a dataframe / dictionary)",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"for idx, row in df.iterrows(): ...")))),Object(i.b)("li",{parentName:"ul"},"Slicing",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get column as Series"),": ",Object(i.b)("inlineCode",{parentName:"li"},'dataframe["column"]'),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Convert series to numpy.ndarray"),": ",Object(i.b)("inlineCode",{parentName:"li"},"series.values")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Extract columns from DF"),": ",Object(i.b)("inlineCode",{parentName:"li"},'dataframe[["column",...]]'),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Dataframe as rows"),": ",Object(i.b)("inlineCode",{parentName:"li"},"dataframe[startIdxIncl: endIdxExcl]")))))),Object(i.b)("li",{parentName:"ul"},"Array based selection",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Select by label"),": ",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"dataframe.loc[label]")," (transposed / series / numpy array)"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"dataframe.loc[[rowLbl1, rowLbl2..* .],[colLbl1, colLbl2...]]")," (tabular / dataframe)"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Select by index, not name"),": Replace loc with iloc",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"df.iloc[<slicing for row>, <slicing for column>]")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Select all rows by column"),": Replace label with ':' ",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"dataframe.loc[<slicing for row>, <slicing for column>]")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"dataframe.loc[:,col]")," (Returns numpy array)"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"dataframe.loc[:,* [cols]]")," (Returns Dataframe)"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"MultiIndexes"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.loc[(top_lvl_idx,2nd_lvl_idx,...), <slicing for column>]"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"e.g. ",Object(i.b)("inlineCode",{parentName:"li"},"sales.loc[('NY',1),:], sales.loc[(slice(None),2),:]")),Object(i.b)("li",{parentName:"ul"},"If you have to use ",Object(i.b)("inlineCode",{parentName:"li"},":")," for slicing, replace the tuple with ",Object(i.b)("inlineCode",{parentName:"li"},"pd.IndexSlice[top_lvl_idx,2nd_lvl_idx,...]"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"e.g. ",Object(i.b)("inlineCode",{parentName:"li"},"df.loc[pd.IndexSlice[:,2nd_lvl_idx,...], <slicing for column>]")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("em",{parentName:"li"},"Datacamp loves to create the alias ",Object(i.b)("inlineCode",{parentName:"em"},"idx=pd.IndexSlice")," to shorten the .loc call.")))),Object(i.b)("li",{parentName:"ul"},"MultiIndexes: the index is an array instead of a single value (think of nested arrays. e.g. arr","[1][2]",", MultiIndex would be (1,2) or something)"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"By Datetime")," (if index is datetime): ",Object(i.b)("inlineCode",{parentName:"li"},"ts0.loc['2010-August':'2010-10-11 22:00:00']")," ",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("em",{parentName:"li"},"can even be like '2010-Aug'")))),Object(i.b)("li",{parentName:"ul"},"(See more: ",Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.w3resource.com/pandas/dataframe/dataframe-loc.php"}),"https://www.w3resource.com/pandas/dataframe/dataframe-loc.php"),")",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"slicing refers to x","[start\ud83d\udd1astep]","."),Object(i.b)("li",{parentName:"ul"},"Special slices:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"[:]"," => Select all"),Object(i.b)("li",{parentName:"ul"},"[n:]"," => from the nth element (inclusive) to the end; note that n starts from 0"),Object(i.b)("li",{parentName:"ul"},"[:n]"," => from the first element to the nth element"))))))))),Object(i.b)("li",{parentName:"ul"},"Conditional Select",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get by bool arr"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df[bool_arr]")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get"),": ",Object(i.b)("inlineCode",{parentName:"li"},'dataframe[dataframe["column"] == condition]')),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Assignment:")," ",Object(i.b)("inlineCode",{parentName:"li"},"df.loc[df['col'] <condition>, 'column_to_set'] = value_to_assign")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Multiple conditional"),": ",Object(i.b)("inlineCode",{parentName:"li"},"(df['col'] == condition) & (df['col'] == condition)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"dataframe[\"col\"] = dataframe['col'] == condition")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"By data type"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.select_dtypes(include=[int, float])")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get data as datetime"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'].dt"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Format datetime"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'].dt.strftime('formatstr')"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"formatstr: e.g. '%Y' to only get the year"))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get data as str"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'] = df['col'].str"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("em",{parentName:"li"},'This can be combined by concatenating string functions behind e.g. .lower(), .strip(), .upper(), .replace(dict), .replace("old","new"), .len()')),Object(i.b)("li",{parentName:"ul"},"Other fun obscure string functions include .startswith()"),Object(i.b)("li",{parentName:"ul"},"Chains must be prefixed with a ",Object(i.b)("inlineCode",{parentName:"li"},".str")," in front e.g. `.str.replace('x','').str.replace(...)"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("em",{parentName:"li"},"Note that these string functions return a df, which can be combined with other str or aggregation functions")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Word count"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'].str.split().str.len()"))))),Object(i.b)("p",null,"Data Addition"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"New Column:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Add new value"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.loc[lbl, col] = val")," (do this for every row to add the column)"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Set column to that value for every row"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'] = val")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Modify by transformation function"),": ",Object(i.b)("inlineCode",{parentName:"li"},'df["newCol"] = df["oldCol"].apply(transformFx)'),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"e.g. ",Object(i.b)("inlineCode",{parentName:"li"},"df.apply(lambda row: row.mean(), axis=1)")),Object(i.b)("li",{parentName:"ul"},"Regex can also be used etc"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Modify by mapping values to a dictionary"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'].map(dict_map_vals)")))),Object(i.b)("li",{parentName:"ul"},"New Row:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Append dataframe"),": ")),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"df1.append(df2,\n    ignore_index=False | True # False: Preserve index. True: Number everything from 0 to n\n)\n"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Concatenating / Joining list of series/dataframes"),": ",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Plus")," (if indexes are properly set): ",Object(i.b)("inlineCode",{parentName:"li"},"df1 + df2")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Concat"),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"pd.concat(list_of_dataframes, # Concatenating a dictionary will result in the keys becoming the indexes\n    axis='index' | 'columns', # 'index': Stack below (\"vertically\"), 'columns': Stack to the right (\"horizontally\")\n    keys=['one','col','name','per','dataframe','in','list'],\n    join='inner',     # optional, keep only rows that share common index labels.\n    ignore_index=bool # If True, prevents repeated integer indices\n)\n"))),Object(i.b)("li",{parentName:"ul"},"Keys: 1 key per DataFrame in the list, forming the outer index in the MultiIndex. The resulting DataFrame will be something like df","['one'][n]"," to access the first DataFrame, df","['col'][n]"," to access the 2nd DataFrame etc."),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Merge / Join"),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"# Inner join, Equivalent to pd.concat([leftDF, rightDF], 'columns', join='inner')\npd.merge(leftDF, rightDF, \n    on=column_label, # See exposition below\n    how='inner',     # Type of join. See below\n    suffixes=[sfx_forDF1, sfx_forDF2] # If both DFs have columns of same name, add suffix at the end if not merging on those columns\n)\n"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"on:")," If multiple columns form the identifier: use ",Object(i.b)("inlineCode",{parentName:"li"},"on=[col1,col2,...]"),". Otherwise, the join will horizontally append copies of the columns even if they are the same."),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"on:")," If df1 and df2 use different labels for the same identifier, use ",Object(i.b)("inlineCode",{parentName:"li"},"left_on")," and ",Object(i.b)("inlineCode",{parentName:"li"},"right_on"),"."),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"how:")," You can also define various types of joins as specified ",Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://mode.com/sql-tutorial/sql-outer-joins/"}),"here")," "),Object(i.b)("li",{parentName:"ul"},"See ",Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html"}),"documentation")," if need to be more specific"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Ordered merge"),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),'# Same as pd.merge above, but designed for ordered data like time series and filling and interpolation.\npd.merge_ordered(leftDF, rightDF,\n    fill_method="ffill" # Forward-filling: Replace NaN entries with the most recent non-null entry,\n    # Other params same as above)\n'))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Merge with value comparison"),Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"pd.merge_asof(...)\n# pd.merge_asof() is like the pd.merge_ordered() function; it merges values in order using the on column\n# but for each row in the left DataFrame, only rows from the right DataFrame whose 'on' column values are less than the left value will be kept.\n")),"Data Deletion"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Drop rows / columns"),": ")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"df.drop(labels,               # Index or column labels to drop. \n    axis= 'index' | 'columns'\n)\n")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Drop rows / columns with missing values"),": ")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"df.dropna(\n    subset = [column_labels]    # Labels along other axis to consider, e.g. if you are dropping rows these would be a list of columns to include.\n    how = 'any' | 'all'         # 'any' : If any NA values are present, drop that row or column. \n                                # 'all' : If all values are NA, drop that row or column.\n\n    thresh = n                  # Drop unless there are at least n non-NA values along that axis\n    axis = 'index' | 'columns'  # 0/\u2018index\u2019   : Drop rows    which contain missing values. \n                                # 1/\u2018columns\u2019 : Drop columns which contain missing values.\n)\n")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"See ",Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html"}),"documentation")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Drop duplicate rows"),": ")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"df.drop_duplicates(\n    subset = arr_of_col_names, \n    keep = 'first' | 'last' | False, \n    inplace = bool\n)\n")),Object(i.b)("p",null,"Value Modification"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Dividing one DF by another"),":",Object(i.b)("pre",{parentName:"li"},Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"DF1.divide(DF2, \n    axis='rows'/'columns' # Divide the DF1 by DF2 along each row\n)\n")))),Object(i.b)("p",null,"Metadata modification"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Re-labelling columns"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.columns = arr_of_labels"))),Object(i.b)("p",null,"Datatype modification"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Convert to datetime"),": ")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"pd.to_datetime(df['col'],\n    format = date_str_format,\n    infer_datetime_format = True | False,  # Infer format based on first non-NaN element. Can increase parsing speed by 5-10x (disabled by default)\n    errors = 'raise' | 'coerce' | 'ignore' # raise = raise exception, coerce = set to NaT (not a time), ignore = ignore\n)\n")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"A datetime column will allow you to manipulate the datetime directly & search for rows that match the date using df.loc",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"You can also extract information from it using its attributes. See any attr under ",Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.month.html"}),"pandas.Series.dt"),".",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Adding a new column for min/year etc"),": ",Object(i.b)("inlineCode",{parentName:"li"},'df["month"] = df["date"].apply(lambda row: row.month)')))))),Object(i.b)("li",{parentName:"ul"},"Example of merging 2 string cols into 1 datetime: ",Object(i.b)("inlineCode",{parentName:"li"},"times_tz_none = pd.to_datetime(la['Date (MM/DD/YYYY)'] + ' ' + la['Wheels-off Time'])")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Convert to numeric"),": ",Object(i.b)("inlineCode",{parentName:"li"},"pd.to_numeric(df['col'], errors='coerce')")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Convert to categorical"),": ")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"df['col'] = pd.Categorical(values=df['col'], categories=arr_of_values, \n    ordered=True # True: ordered categoricals\n)\n")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Bin values into discrete intervals (Convert numbers to categories)"),": ")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"df['col'] = pd.cut(df['col'], \n    bins = arr_of_bin_edges,    # e.g. [0, 60, 180, np.inf]\n    labels = arr_of_categories  # e.g. ['short', 'medium', 'long']\n)\n# Alternatively, if you just want to cut them into equal sized bins\ndf['col'] = pd.cut(df['col'], \n    bins = bin_counts\n)\n")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Convert to other types"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['newCol'] = df['dataCol'].astype('type')"))),Object(i.b)("p",null,"Datetime timezone modification"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Localizing timezone"),": ",Object(i.b)("inlineCode",{parentName:"li"},'series.dt.tz_localize("US/Central")')),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Converting timezone"),": ",Object(i.b)("inlineCode",{parentName:"li"},'series.dt.tz_convert("US/Central")'))),Object(i.b)("p",null,"Operations that involve boolean arrays:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Operations that convert DF into boolean DF:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Value meets condition"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df_bool_arr = df['col'] > val")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Value membership"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'].isin(arr_of_acceptable_values)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Value is null or NA"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.isnull()")," or ",Object(i.b)("inlineCode",{parentName:"li"},"df.isna()")," (they are the same)"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Value is not null"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.notnull()")," or ",Object(i.b)("inlineCode",{parentName:"li"},"df.notna()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Row is duplicated"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.duplicated(subset = arr_of_col_names, keep = 'first' | 'last' | False)")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Negate boolean array"),": ",Object(i.b)("inlineCode",{parentName:"li"},"~bool_arr")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Subsetting with bool array"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df[bool_df]"))),Object(i.b)("p",null,"Unary Operations"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Compute % change from the immediate previous"),": ",Object(i.b)("inlineCode",{parentName:"li"},"series.pct_change(offset=1)"),": ",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Row by default. Useful in comparing the percentage of change in a time series of elements. "),Object(i.b)("li",{parentName:"ul"},"Offset is in unit time specified in sample")))),Object(i.b)("p",null,"Grouping Data"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Downsample time series"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'].resample(time_str_format).agg_fx()"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"e.g. ",Object(i.b)("inlineCode",{parentName:"li"},"df.Temperature.resample('6h').mean()")," = group an hourly based time series into averaged quarterly data"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"df.resample('A').mean()"),": resample w/ annual frequency, assumes index is a datetime"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"df.resample('A', on=column_label).mean()"),": resample w.r.t a column label that isn't the index"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"groupby")," function:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Group-by (Single index)"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.groupby('idx')")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Group-by (Multi-Index)"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.groupby([indexes])")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Group-by (Rows)"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.groupby(pd.Series(['row_vals'])")),Object(i.b)("li",{parentName:"ul"},"Note that the groupby function should be followed up with a column + aggregate for it to be useful, unless you want to literally count the number of rows etc",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"e.g. count_by_class = by_class","['survived']",".count()"))),Object(i.b)("li",{parentName:"ul"},"Group by Day example: ",Object(i.b)("inlineCode",{parentName:"li"},"by_day = sales.groupby(sales.index.strftime('%a'))")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Multiple Aggregation (columns)"),": ",Object(i.b)("inlineCode",{parentName:"li"},"sales.groupby('city')[['bread','butter']].max()"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("img",{src:a(162).default})))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Multiple aggregation (functions)"),": ",Object(i.b)("inlineCode",{parentName:"li"},"sales.groupby('city')[['bread','butter']].agg(['max','sum'])"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("img",{src:a(163).default})),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Custom aggregation (own function)"),": You can define a function that accepts a Series and returns a single value."),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Separate aggregation per column (dictionary)"),": You can define a dictionary and put it into .agg; the key is the column, the value is the aggregation function (e.g. max, min)"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"df.groupby(...).transform(fx)"),": Transform after aggregation (group by, then transform values based on their groups)",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Output is the same shape as before groupby."),Object(i.b)("li",{parentName:"ul"},"e.g. `def zscore(series): return (series - series.mean()) / series.std()"),Object(i.b)("li",{parentName:"ul"},"Usage: ",Object(i.b)("inlineCode",{parentName:"li"},"df.groupby('x')['y'].transform(zscore)")))))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Filtering (after groupby)"),":",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},'by_company = sales.groupby("Company")')),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Compute sum of 'Units'"),": ",Object(i.b)("inlineCode",{parentName:"li"},"by_com_sum = sales['Units'].sum()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Filter 'Units' where sum > 35"),": ",Object(i.b)("inlineCode",{parentName:"li"},"by_com_filt = by_company.filter(lambda g:g['Units'].sum() > 35)"))))),Object(i.b)("p",null,"Aggregation Operations"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Get Uniques"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.unique()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Aggregate duplicates"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.groupby(by = arr_of_col_names).agg(col_to_fx_dict).reset_index()"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("em",{parentName:"li"},"col_to_fx_dict"),": e.g. {'height: 'max', 'weight': mean}"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"sum"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'].sum(axis={index (0), columns (1)})"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("em",{parentName:"li"},"You can also sum booleans to count number of True values")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Count number of missing values by col"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.isna().sum()")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"mean"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'].mean()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"max"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'].max()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"argmax")," (idx of max val): ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'].argmax()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"count"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'].count()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"quantile"),": ",Object(i.b)("inlineCode",{parentName:"li"},"quantile([start, end (0-1)])"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Get single value: ",Object(i.b)("inlineCode",{parentName:"li"},"quantile(pct_from_0_to_1)")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"std.dev"),": ",Object(i.b)("inlineCode",{parentName:"li"},"std()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"rolling mean"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df['col'].rolling(window=numRows).mean()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"# of uniques:")," ",Object(i.b)("inlineCode",{parentName:"li"},"nunique()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Count number of times value appeared"),": ",Object(i.b)("inlineCode",{parentName:"li"},"value_counts()")," / ",Object(i.b)("inlineCode",{parentName:"li"},"series.value_counts()"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Returns dataframe (dictionary)\nSorting Operations"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Sort by current index"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.sort_index(level=idx_lvl)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"You may want to change the index by using ",Object(i.b)("inlineCode",{parentName:"li"},"df.set_index()")," first"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Sort values by column name"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.sort_values(by = arr_of_col_names)")," or ",Object(i.b)("inlineCode",{parentName:"li"},"df.sort_values('col')"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Sort df chosen by boolean array"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df[bool_arr].sort_values(...)"))))),Object(i.b)("p",null,"Windowing Operations"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://pandas.pydata.org/pandas-docs/stable/user_guide/computation.html"}),"Documentation")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"df.expanding()"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"See ",Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://stackoverflow.com/questions/45370666/what-are-pandas-expanding-window-functions"}),"this"),': "A common alternative to rolling statistics is to use an expanding window, which yields the value of the statistic with all the data available up to that point in time"')))),Object(i.b)("p",null,"Operations on Indexes:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Interpolate"),": ",Object(i.b)("inlineCode",{parentName:"li"},"ts2_interp = ts2.reindex(ts1.index).interpolate(how='linear') "),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"in the above example, the index is changed to datetime. ts1 contains all datetime, ts2 has some missing data"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Changing metadata / restructuring"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Reindex")," (Change values of the 1st column): ",Object(i.b)("inlineCode",{parentName:"li"},"df = df.reindex(col/df2.index,[method=pad/backfill/nearest])"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("em",{parentName:"li"},"Conform DataFrame to new index with optional filling logic, placing NA/NaN in locations having no value in the previous index. A new object is produced unless the new index is equivalent to the current one and copy=False")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Change index entirely"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.set_index('colname',inplace=bool)"),". ",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"This is usually done as an interim operation to make naivgating the DF easier, or for using ",Object(i.b)("inlineCode",{parentName:"li"},"sort_index()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://stackoverflow.com/questions/50741330/difference-between-df-reindex-and-df-set-index-methods-in-pandas"}),"Reindex vs set_index")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Reset index"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.reset_index()"))))),Object(i.b)("p",null,"Operations on Restructuring Data (Pivoting)"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Pivot (reorder data by changing the index, columns & values. REQUIRES UNIQUE INDEX)"),": ")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"df.pivot(\n    index=new_row_index,      # Each unique value in the column is now a primary key of the row. Aggfunc aggregates if there are duplicate PKs.\n    columns=new_columns,      # Each unique value in the column is now a column\n    values=old_cols_to_vals   # Each value in the column are now assigned to row-column where they occur. Aggregate if needed. \n)\n")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Pivot Table: Same as pivot, but deal with duplicate index values with a reduction using aggfunc"),":")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"df.pivot_table(\n    index=new_row_index,        # Each unique value in the column is now a primary key of the row. Aggfunc aggregates if there are duplicate PKs.\n    columns=new_columns,        # Each unique value in the column is now a column\n    values=old_cols_to_vals     # Each value in the column are now assigned to row-column where they occur. Aggregate if needed. \n    aggfunc=fx/'predefined_fx', # Aggregate duplicate index values using this function\n    margins=bool                # If True, add a \"All\" row at the bottom which aggregates all data\n)\n")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Melt: undoing a pivot"),": ")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"pd.melt(dataframe, \n    id_vars=['cols'],               # column names to keep as columns\n    value_vars=['cols'],            # column names to convert into key-value pairs, under two columns: \n                                    # 1st column specified as \"variable\" which uses the original column name\n    value_name=['value_col_names'], # 2nd column whose name is specified by value_name\n    col_level = 0                   # use col_level = 0 to convert it into purely variable-value pair, removing any id_vars / indexes currently in use\n)\n")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://pandas.pydata.org/docs/reference/api/pandas.melt.html"}),"documentation")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Stack"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.stack(level='col')"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.w3resource.com/pandas/dataframe/dataframe-stack.php"}),"stack the prescribed level(s) by shifting columns to index")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Unstacking"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.unstack(level='col'/num)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.w3resource.com/pandas/dataframe/dataframe-unstack.php"}),"form new level of columns whose inner-most level consists of the pivoted index labels")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Swap level"),": ",Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.geeksforgeeks.org/python-pandas-multiindex-swaplevel/"}),"swap ordering of stacked levels"))),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{}),"dataframe.swaplevel(\n    index1_level, # e.g. 0 for the outer-most level\n    index2_level, # e.g. 1 for the inner level\n    axis='index'|'columns')\n")),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Operations involving missing values and cleaning data:"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Impute/Replace missing vals"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.fillna({'col' : val_arr}, inplace=True)"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"See ",Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html?highlight=fillna#pandas.DataFrame.fillna"}),"documentation"))))),Object(i.b)("p",null,"Operations involving visualization "),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"DataFrame Info",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Correlation between columns"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.corr()")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Display head"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.head(<rows=5>)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Display tail"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.tail(<rows=5>)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Display schema"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.info()")," (Shows col name, non-null entries & datatype)",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Display columns"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.columns")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Display summary stats (e.g. std,min,max,quartiles)"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.describe()")," (also works on columns of the df)"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Display datatype"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.dtype")," or ",Object(i.b)("inlineCode",{parentName:"li"},"df.dtypes")," (works on columns of the df)"),Object(i.b)("li",{parentName:"ul"},Object(i.b)("strong",{parentName:"li"},"Size / Length / Shape"),": ",Object(i.b)("inlineCode",{parentName:"li"},"df.shape")))),Object(i.b)("li",{parentName:"ul"},"Plotting data from DataFrame (See matplotlib.pyplot):",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"dataframe.plot(kind='scatter', x='col1', y='col2', [color='str', s=size_value,subplots=bool])"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"you can plot all data by omitting x and y"),Object(i.b)("li",{parentName:"ul"},"subplots: plot in separate graphs"))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"dataframe.boxplot(column = [y_axis_col_values], by=[x_axis_col_values])")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"ax = df[list_of_columns].plot() "),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"You can customize the plot by calling the functions below on ax:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},'ax.set_ylabel("% Change of Host Country Medal Count")')),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},'ax.set_title("Is there a Host Country Advantage?")')),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"ax.set_xticklabels(editions['City'])")))),Object(i.b)("li",{parentName:"ul"},"plot all of the columns (their x and y) on the same graph with their own colours"),Object(i.b)("li",{parentName:"ul"},"plt.title(str)"),Object(i.b)("li",{parentName:"ul"},"plt.xlabel(str)"),Object(i.b)("li",{parentName:"ul"},"plt.ylabel(str)"),Object(i.b)("li",{parentName:"ul"},"plt.show()"))),Object(i.b)("li",{parentName:"ul"},"Subplots",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"fig, axes = plt.subplots(nrows=num_of_rows, ncols=num_of_columns)")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"df.plot(ax=axes[0], kind='hist', normed=True, bins=30, range=(0,.3))")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"df.fraction.plot(ax=axes[1], kind='hist', normed=True, cumulative=True, bins=30, range=(0,.3))"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"kind='bar'"))))))))))}p.isMDXComponent=!0}}]);